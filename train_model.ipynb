{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 976, Validation batches: 279\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# If using your custom data loader, import it (or define your own here)\n",
    "from data import build_split_dataloaders  # ...existing code...\n",
    "from model import SwinTransformerClassificationModel  # New import for SwinTransformer\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 6\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "experiment = \"convnextv2\"\n",
    "log_dir = f\"runs/{experiment}\"\n",
    "\n",
    "# Data paths\n",
    "root_dir = os.path.join(\"K:\", \"rsna-breast-cancer-detection\")\n",
    "csv_path = os.path.join(root_dir, \"train.csv\")\n",
    "root_dir = os.path.join(root_dir, \"train_images_cropped\")\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # RESIZE TO 224x224\n",
    "    transforms.Resize((384, 384)),\n",
    "])\n",
    "\n",
    "# Build dataloaders (Assumes build_split_dataloaders is defined in data.py)\n",
    "train_loader, val_loader, test_loader = build_split_dataloaders(\n",
    "    csv_path, root_dir, batch_size=batch_size, transform=transform, train=True, val_ratio=0.2, test_ratio=0.1, paired=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    8756\n",
      "1.0    6266\n",
      "2.0    1692\n",
      "Name: count, dtype: int64\n",
      "tensor([0.1321, 0.1845, 0.6834], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from data import MedicalImageDataset\n",
    "\n",
    "# Create a new dataset to check the class distribution\n",
    "dataset = MedicalImageDataset(csv_path, root_dir, transform=transform, paired=True)\n",
    "dataframe = dataset.metadata\n",
    "cc_birads = dataframe[\"cc_birads\"].values\n",
    "mlo_birads = dataframe[\"mlo_birads\"].values\n",
    "\n",
    "birads_counts = cc_birads.tolist() + mlo_birads.tolist()\n",
    "birads_counts = pd.Series(birads_counts).value_counts()\n",
    "\n",
    "print(birads_counts)\n",
    "\n",
    "# Create weights for loss function based on class distribution\n",
    "birads_weights = 1 / birads_counts\n",
    "birads_weights = birads_weights / birads_weights.sum()\n",
    "birads_weights = birads_weights.sort_index()\n",
    "\n",
    "birads_weights = torch.tensor(birads_weights.values).float()\n",
    "birads_weights = birads_weights.to(\"cuda\")\n",
    "\n",
    "print(birads_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from model import SwinTransformerClassificationModel, SwinMammoClassifier, ConvNeXtClassificationModel\n",
    "# Initialize model, criterion, optimizer, and TensorBoard writer\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# model = SwinTransformerClassificationModel(num_classes=num_classes)\n",
    "# model = SwinMammoClassifier(num_classes=num_classes)\n",
    "model = ConvNeXtClassificationModel(num_classes=num_classes)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 10] loss: 1.410  accuracy: 0.433 total accuracy: 0.433 avg loss: 2.819\n",
      "[Epoch 1, Batch 20] loss: 1.228  accuracy: 0.467 total accuracy: 0.450 avg loss: 2.638\n",
      "[Epoch 1, Batch 30] loss: 1.047  accuracy: 0.400 total accuracy: 0.433 avg loss: 2.456\n",
      "[Epoch 1, Batch 40] loss: 0.995  accuracy: 0.517 total accuracy: 0.454 avg loss: 2.340\n",
      "[Epoch 1, Batch 50] loss: 0.889  accuracy: 0.583 total accuracy: 0.480 avg loss: 2.227\n",
      "[Epoch 1, Batch 60] loss: 0.950  accuracy: 0.583 total accuracy: 0.497 avg loss: 2.173\n",
      "[Epoch 1, Batch 70] loss: 0.952  accuracy: 0.583 total accuracy: 0.510 avg loss: 2.135\n",
      "[Epoch 1, Batch 80] loss: 1.002  accuracy: 0.400 total accuracy: 0.496 avg loss: 2.118\n",
      "[Epoch 1, Batch 90] loss: 0.969  accuracy: 0.583 total accuracy: 0.506 avg loss: 2.098\n",
      "[Epoch 1, Batch 100] loss: 1.028  accuracy: 0.350 total accuracy: 0.490 avg loss: 2.094\n",
      "[Epoch 1, Batch 110] loss: 0.870  accuracy: 0.617 total accuracy: 0.502 avg loss: 2.062\n",
      "[Epoch 1, Batch 120] loss: 0.970  accuracy: 0.500 total accuracy: 0.501 avg loss: 2.052\n",
      "[Epoch 1, Batch 130] loss: 0.951  accuracy: 0.500 total accuracy: 0.501 avg loss: 2.040\n",
      "[Epoch 1, Batch 140] loss: 0.877  accuracy: 0.650 total accuracy: 0.512 avg loss: 2.020\n",
      "[Epoch 1, Batch 150] loss: 0.968  accuracy: 0.600 total accuracy: 0.518 avg loss: 2.014\n",
      "[Epoch 1, Batch 160] loss: 1.194  accuracy: 0.400 total accuracy: 0.510 avg loss: 2.037\n",
      "[Epoch 1, Batch 170] loss: 1.167  accuracy: 0.550 total accuracy: 0.513 avg loss: 2.055\n",
      "[Epoch 1, Batch 180] loss: 1.163  accuracy: 0.417 total accuracy: 0.507 avg loss: 2.070\n",
      "[Epoch 1, Batch 190] loss: 0.951  accuracy: 0.533 total accuracy: 0.509 avg loss: 2.061\n",
      "[Epoch 1, Batch 200] loss: 1.029  accuracy: 0.433 total accuracy: 0.505 avg loss: 2.061\n",
      "[Epoch 1, Batch 210] loss: 1.003  accuracy: 0.500 total accuracy: 0.505 avg loss: 2.058\n",
      "[Epoch 1, Batch 220] loss: 0.951  accuracy: 0.617 total accuracy: 0.510 avg loss: 2.051\n",
      "[Epoch 1, Batch 230] loss: 0.931  accuracy: 0.467 total accuracy: 0.508 avg loss: 2.043\n",
      "[Epoch 1, Batch 240] loss: 0.949  accuracy: 0.500 total accuracy: 0.508 avg loss: 2.037\n",
      "[Epoch 1, Batch 250] loss: 1.019  accuracy: 0.383 total accuracy: 0.503 avg loss: 2.037\n",
      "[Epoch 1, Batch 260] loss: 0.966  accuracy: 0.417 total accuracy: 0.499 avg loss: 2.033\n",
      "[Epoch 1, Batch 270] loss: 1.037  accuracy: 0.517 total accuracy: 0.500 avg loss: 2.034\n",
      "[Epoch 1, Batch 280] loss: 1.023  accuracy: 0.467 total accuracy: 0.499 avg loss: 2.035\n",
      "[Epoch 1, Batch 290] loss: 1.201  accuracy: 0.500 total accuracy: 0.499 avg loss: 2.048\n",
      "[Epoch 1, Batch 300] loss: 1.159  accuracy: 0.433 total accuracy: 0.497 avg loss: 2.057\n",
      "[Epoch 1, Batch 310] loss: 0.988  accuracy: 0.500 total accuracy: 0.497 avg loss: 2.054\n",
      "[Epoch 1, Batch 320] loss: 0.975  accuracy: 0.617 total accuracy: 0.501 avg loss: 2.051\n",
      "[Epoch 1, Batch 330] loss: 0.892  accuracy: 0.583 total accuracy: 0.503 avg loss: 2.043\n",
      "[Epoch 1, Batch 340] loss: 0.989  accuracy: 0.450 total accuracy: 0.501 avg loss: 2.041\n",
      "[Epoch 1, Batch 350] loss: 1.109  accuracy: 0.567 total accuracy: 0.503 avg loss: 2.046\n",
      "[Epoch 1, Batch 360] loss: 0.930  accuracy: 0.500 total accuracy: 0.503 avg loss: 2.041\n",
      "[Epoch 1, Batch 370] loss: 1.071  accuracy: 0.367 total accuracy: 0.500 avg loss: 2.043\n",
      "[Epoch 1, Batch 380] loss: 0.941  accuracy: 0.450 total accuracy: 0.498 avg loss: 2.039\n",
      "[Epoch 1, Batch 390] loss: 1.078  accuracy: 0.450 total accuracy: 0.497 avg loss: 2.042\n",
      "[Epoch 1, Batch 400] loss: 1.040  accuracy: 0.600 total accuracy: 0.500 avg loss: 2.043\n",
      "[Epoch 1, Batch 410] loss: 1.034  accuracy: 0.600 total accuracy: 0.502 avg loss: 2.044\n",
      "[Epoch 1, Batch 420] loss: 1.068  accuracy: 0.350 total accuracy: 0.498 avg loss: 2.046\n",
      "[Epoch 1, Batch 430] loss: 1.013  accuracy: 0.500 total accuracy: 0.498 avg loss: 2.045\n",
      "[Epoch 1, Batch 440] loss: 0.941  accuracy: 0.383 total accuracy: 0.496 avg loss: 2.042\n",
      "[Epoch 1, Batch 450] loss: 1.067  accuracy: 0.467 total accuracy: 0.495 avg loss: 2.044\n",
      "[Epoch 1, Batch 460] loss: 1.015  accuracy: 0.450 total accuracy: 0.494 avg loss: 2.043\n",
      "[Epoch 1, Batch 470] loss: 1.008  accuracy: 0.567 total accuracy: 0.496 avg loss: 2.043\n",
      "[Epoch 1, Batch 480] loss: 1.008  accuracy: 0.517 total accuracy: 0.496 avg loss: 2.042\n",
      "[Epoch 1, Batch 490] loss: 0.953  accuracy: 0.483 total accuracy: 0.496 avg loss: 2.040\n",
      "[Epoch 1, Batch 500] loss: 1.001  accuracy: 0.450 total accuracy: 0.495 avg loss: 2.039\n",
      "[Epoch 1, Batch 510] loss: 0.992  accuracy: 0.517 total accuracy: 0.495 avg loss: 2.038\n",
      "[Epoch 1, Batch 520] loss: 1.058  accuracy: 0.400 total accuracy: 0.494 avg loss: 2.039\n",
      "[Epoch 1, Batch 530] loss: 0.932  accuracy: 0.500 total accuracy: 0.494 avg loss: 2.036\n",
      "[Epoch 1, Batch 540] loss: 1.016  accuracy: 0.517 total accuracy: 0.494 avg loss: 2.036\n",
      "[Epoch 1, Batch 550] loss: 0.963  accuracy: 0.450 total accuracy: 0.493 avg loss: 2.034\n",
      "[Epoch 1, Batch 560] loss: 1.043  accuracy: 0.450 total accuracy: 0.493 avg loss: 2.035\n",
      "[Epoch 1, Batch 570] loss: 0.944  accuracy: 0.583 total accuracy: 0.494 avg loss: 2.032\n",
      "[Epoch 1, Batch 580] loss: 1.007  accuracy: 0.450 total accuracy: 0.493 avg loss: 2.032\n",
      "[Epoch 1, Batch 590] loss: 1.021  accuracy: 0.483 total accuracy: 0.493 avg loss: 2.032\n",
      "[Epoch 1, Batch 600] loss: 0.966  accuracy: 0.583 total accuracy: 0.495 avg loss: 2.030\n",
      "[Epoch 1, Batch 610] loss: 0.905  accuracy: 0.600 total accuracy: 0.496 avg loss: 2.027\n",
      "[Epoch 1, Batch 620] loss: 1.093  accuracy: 0.350 total accuracy: 0.494 avg loss: 2.029\n",
      "[Epoch 1, Batch 630] loss: 0.901  accuracy: 0.517 total accuracy: 0.494 avg loss: 2.026\n",
      "[Epoch 1, Batch 640] loss: 0.944  accuracy: 0.367 total accuracy: 0.492 avg loss: 2.024\n",
      "[Epoch 1, Batch 650] loss: 0.878  accuracy: 0.533 total accuracy: 0.493 avg loss: 2.019\n",
      "[Epoch 1, Batch 660] loss: 0.853  accuracy: 0.483 total accuracy: 0.493 avg loss: 2.015\n",
      "[Epoch 1, Batch 670] loss: 0.995  accuracy: 0.467 total accuracy: 0.493 avg loss: 2.014\n",
      "[Epoch 1, Batch 680] loss: 1.031  accuracy: 0.433 total accuracy: 0.492 avg loss: 2.015\n",
      "[Epoch 1, Batch 690] loss: 0.972  accuracy: 0.467 total accuracy: 0.491 avg loss: 2.014\n",
      "[Epoch 1, Batch 700] loss: 0.957  accuracy: 0.533 total accuracy: 0.492 avg loss: 2.013\n",
      "[Epoch 1, Batch 710] loss: 0.983  accuracy: 0.383 total accuracy: 0.490 avg loss: 2.012\n",
      "[Epoch 1, Batch 720] loss: 0.981  accuracy: 0.383 total accuracy: 0.489 avg loss: 2.011\n",
      "[Epoch 1, Batch 730] loss: 0.944  accuracy: 0.467 total accuracy: 0.489 avg loss: 2.010\n",
      "[Epoch 1, Batch 740] loss: 0.897  accuracy: 0.550 total accuracy: 0.489 avg loss: 2.007\n",
      "[Epoch 1, Batch 750] loss: 0.923  accuracy: 0.483 total accuracy: 0.489 avg loss: 2.004\n",
      "[Epoch 1, Batch 760] loss: 0.976  accuracy: 0.483 total accuracy: 0.489 avg loss: 2.004\n",
      "[Epoch 1, Batch 770] loss: 0.979  accuracy: 0.600 total accuracy: 0.491 avg loss: 2.003\n",
      "[Epoch 1, Batch 780] loss: 1.077  accuracy: 0.483 total accuracy: 0.491 avg loss: 2.005\n",
      "[Epoch 1, Batch 790] loss: 0.948  accuracy: 0.517 total accuracy: 0.491 avg loss: 2.004\n",
      "[Epoch 1, Batch 800] loss: 1.170  accuracy: 0.400 total accuracy: 0.490 avg loss: 2.008\n",
      "[Epoch 1, Batch 810] loss: 1.010  accuracy: 0.550 total accuracy: 0.491 avg loss: 2.008\n",
      "[Epoch 1, Batch 820] loss: 0.907  accuracy: 0.500 total accuracy: 0.491 avg loss: 2.006\n",
      "[Epoch 1, Batch 830] loss: 1.086  accuracy: 0.433 total accuracy: 0.490 avg loss: 2.008\n",
      "[Epoch 1, Batch 840] loss: 0.925  accuracy: 0.567 total accuracy: 0.491 avg loss: 2.006\n",
      "[Epoch 1, Batch 850] loss: 0.973  accuracy: 0.467 total accuracy: 0.491 avg loss: 2.005\n",
      "[Epoch 1, Batch 860] loss: 1.114  accuracy: 0.517 total accuracy: 0.491 avg loss: 2.008\n",
      "[Epoch 1, Batch 870] loss: 0.964  accuracy: 0.500 total accuracy: 0.491 avg loss: 2.007\n",
      "[Epoch 1, Batch 880] loss: 1.002  accuracy: 0.367 total accuracy: 0.490 avg loss: 2.007\n",
      "[Epoch 1, Batch 890] loss: 1.051  accuracy: 0.450 total accuracy: 0.489 avg loss: 2.008\n",
      "[Epoch 1, Batch 900] loss: 1.042  accuracy: 0.333 total accuracy: 0.487 avg loss: 2.009\n",
      "[Epoch 1, Batch 910] loss: 1.130  accuracy: 0.417 total accuracy: 0.487 avg loss: 2.011\n",
      "[Epoch 1, Batch 920] loss: 0.953  accuracy: 0.500 total accuracy: 0.487 avg loss: 2.010\n",
      "[Epoch 1, Batch 930] loss: 1.033  accuracy: 0.400 total accuracy: 0.486 avg loss: 2.011\n",
      "[Epoch 1, Batch 940] loss: 1.069  accuracy: 0.450 total accuracy: 0.485 avg loss: 2.012\n",
      "[Epoch 1, Batch 950] loss: 0.954  accuracy: 0.567 total accuracy: 0.486 avg loss: 2.011\n",
      "[Epoch 1, Batch 960] loss: 1.069  accuracy: 0.383 total accuracy: 0.485 avg loss: 2.012\n",
      "[Epoch 1, Batch 970] loss: 1.152  accuracy: 0.550 total accuracy: 0.486 avg loss: 2.015\n",
      "Epoch 1 completed in 1356.26 seconds\n",
      "Validation loss after epoch 1: 2.016  accuracy: 0.531\n",
      "[Epoch 2, Batch 10] loss: 1.000  accuracy: 0.567 total accuracy: 0.567 avg loss: 2.000\n",
      "[Epoch 2, Batch 20] loss: 0.989  accuracy: 0.383 total accuracy: 0.475 avg loss: 1.989\n",
      "[Epoch 2, Batch 30] loss: 0.870  accuracy: 0.550 total accuracy: 0.500 avg loss: 1.906\n",
      "[Epoch 2, Batch 40] loss: 0.995  accuracy: 0.533 total accuracy: 0.508 avg loss: 1.927\n",
      "[Epoch 2, Batch 50] loss: 0.946  accuracy: 0.633 total accuracy: 0.533 avg loss: 1.920\n",
      "[Epoch 2, Batch 60] loss: 0.908  accuracy: 0.500 total accuracy: 0.528 avg loss: 1.902\n",
      "[Epoch 2, Batch 70] loss: 1.128  accuracy: 0.433 total accuracy: 0.514 avg loss: 1.953\n",
      "[Epoch 2, Batch 80] loss: 1.127  accuracy: 0.467 total accuracy: 0.508 avg loss: 1.991\n",
      "[Epoch 2, Batch 90] loss: 1.102  accuracy: 0.367 total accuracy: 0.493 avg loss: 2.014\n",
      "[Epoch 2, Batch 100] loss: 1.074  accuracy: 0.583 total accuracy: 0.502 avg loss: 2.028\n",
      "[Epoch 2, Batch 110] loss: 0.993  accuracy: 0.533 total accuracy: 0.505 avg loss: 2.024\n",
      "[Epoch 2, Batch 120] loss: 1.204  accuracy: 0.383 total accuracy: 0.494 avg loss: 2.056\n",
      "[Epoch 2, Batch 130] loss: 0.780  accuracy: 0.683 total accuracy: 0.509 avg loss: 2.018\n",
      "[Epoch 2, Batch 140] loss: 0.977  accuracy: 0.467 total accuracy: 0.506 avg loss: 2.013\n",
      "[Epoch 2, Batch 150] loss: 0.938  accuracy: 0.567 total accuracy: 0.510 avg loss: 2.004\n",
      "[Epoch 2, Batch 160] loss: 0.992  accuracy: 0.467 total accuracy: 0.507 avg loss: 2.003\n",
      "[Epoch 2, Batch 170] loss: 0.947  accuracy: 0.583 total accuracy: 0.512 avg loss: 1.996\n",
      "[Epoch 2, Batch 180] loss: 0.981  accuracy: 0.533 total accuracy: 0.513 avg loss: 1.994\n",
      "[Epoch 2, Batch 190] loss: 0.947  accuracy: 0.583 total accuracy: 0.517 avg loss: 1.989\n",
      "[Epoch 2, Batch 200] loss: 0.934  accuracy: 0.533 total accuracy: 0.517 avg loss: 1.983\n",
      "[Epoch 2, Batch 210] loss: 0.910  accuracy: 0.600 total accuracy: 0.521 avg loss: 1.975\n",
      "[Epoch 2, Batch 220] loss: 0.808  accuracy: 0.567 total accuracy: 0.523 avg loss: 1.959\n",
      "[Epoch 2, Batch 230] loss: 1.027  accuracy: 0.550 total accuracy: 0.525 avg loss: 1.963\n",
      "[Epoch 2, Batch 240] loss: 0.930  accuracy: 0.517 total accuracy: 0.524 avg loss: 1.959\n",
      "[Epoch 2, Batch 250] loss: 0.965  accuracy: 0.450 total accuracy: 0.521 avg loss: 1.958\n",
      "[Epoch 2, Batch 260] loss: 0.952  accuracy: 0.517 total accuracy: 0.521 avg loss: 1.956\n",
      "[Epoch 2, Batch 270] loss: 0.895  accuracy: 0.500 total accuracy: 0.520 avg loss: 1.950\n",
      "[Epoch 2, Batch 280] loss: 1.037  accuracy: 0.417 total accuracy: 0.517 avg loss: 1.954\n",
      "[Epoch 2, Batch 290] loss: 1.038  accuracy: 0.483 total accuracy: 0.516 avg loss: 1.958\n",
      "[Epoch 2, Batch 300] loss: 0.970  accuracy: 0.367 total accuracy: 0.511 avg loss: 1.958\n",
      "[Epoch 2, Batch 310] loss: 1.030  accuracy: 0.350 total accuracy: 0.505 avg loss: 1.961\n",
      "[Epoch 2, Batch 320] loss: 0.939  accuracy: 0.583 total accuracy: 0.508 avg loss: 1.958\n",
      "[Epoch 2, Batch 330] loss: 0.928  accuracy: 0.467 total accuracy: 0.507 avg loss: 1.955\n",
      "[Epoch 2, Batch 340] loss: 0.952  accuracy: 0.400 total accuracy: 0.503 avg loss: 1.954\n",
      "[Epoch 2, Batch 350] loss: 1.103  accuracy: 0.417 total accuracy: 0.501 avg loss: 1.961\n",
      "[Epoch 2, Batch 360] loss: 0.998  accuracy: 0.533 total accuracy: 0.502 avg loss: 1.962\n",
      "[Epoch 2, Batch 370] loss: 0.975  accuracy: 0.600 total accuracy: 0.505 avg loss: 1.961\n",
      "[Epoch 2, Batch 380] loss: 1.024  accuracy: 0.350 total accuracy: 0.500 avg loss: 1.964\n",
      "[Epoch 2, Batch 390] loss: 0.805  accuracy: 0.567 total accuracy: 0.502 avg loss: 1.955\n",
      "[Epoch 2, Batch 400] loss: 1.061  accuracy: 0.300 total accuracy: 0.497 avg loss: 1.959\n",
      "[Epoch 2, Batch 410] loss: 1.096  accuracy: 0.500 total accuracy: 0.497 avg loss: 1.965\n",
      "[Epoch 2, Batch 420] loss: 0.857  accuracy: 0.617 total accuracy: 0.500 avg loss: 1.959\n",
      "[Epoch 2, Batch 430] loss: 0.958  accuracy: 0.517 total accuracy: 0.500 avg loss: 1.958\n",
      "[Epoch 2, Batch 440] loss: 0.991  accuracy: 0.483 total accuracy: 0.500 avg loss: 1.958\n",
      "[Epoch 2, Batch 450] loss: 0.939  accuracy: 0.500 total accuracy: 0.500 avg loss: 1.956\n",
      "[Epoch 2, Batch 460] loss: 0.932  accuracy: 0.517 total accuracy: 0.500 avg loss: 1.954\n",
      "[Epoch 2, Batch 470] loss: 1.048  accuracy: 0.517 total accuracy: 0.501 avg loss: 1.957\n",
      "[Epoch 2, Batch 480] loss: 0.960  accuracy: 0.467 total accuracy: 0.500 avg loss: 1.957\n",
      "[Epoch 2, Batch 490] loss: 1.028  accuracy: 0.450 total accuracy: 0.499 avg loss: 1.959\n",
      "[Epoch 2, Batch 500] loss: 0.933  accuracy: 0.450 total accuracy: 0.498 avg loss: 1.957\n",
      "[Epoch 2, Batch 510] loss: 1.042  accuracy: 0.367 total accuracy: 0.495 avg loss: 1.959\n",
      "[Epoch 2, Batch 520] loss: 0.905  accuracy: 0.517 total accuracy: 0.496 avg loss: 1.956\n",
      "[Epoch 2, Batch 530] loss: 1.002  accuracy: 0.550 total accuracy: 0.497 avg loss: 1.957\n",
      "[Epoch 2, Batch 540] loss: 1.034  accuracy: 0.450 total accuracy: 0.496 avg loss: 1.959\n",
      "[Epoch 2, Batch 550] loss: 0.927  accuracy: 0.350 total accuracy: 0.493 avg loss: 1.957\n",
      "[Epoch 2, Batch 560] loss: 0.916  accuracy: 0.617 total accuracy: 0.496 avg loss: 1.955\n",
      "[Epoch 2, Batch 570] loss: 0.918  accuracy: 0.533 total accuracy: 0.496 avg loss: 1.953\n",
      "[Epoch 2, Batch 580] loss: 0.825  accuracy: 0.700 total accuracy: 0.500 avg loss: 1.948\n",
      "[Epoch 2, Batch 590] loss: 0.923  accuracy: 0.600 total accuracy: 0.501 avg loss: 1.946\n",
      "[Epoch 2, Batch 600] loss: 0.903  accuracy: 0.600 total accuracy: 0.503 avg loss: 1.944\n",
      "[Epoch 2, Batch 610] loss: 0.989  accuracy: 0.500 total accuracy: 0.503 avg loss: 1.944\n",
      "[Epoch 2, Batch 620] loss: 0.954  accuracy: 0.583 total accuracy: 0.504 avg loss: 1.944\n",
      "[Epoch 2, Batch 630] loss: 0.933  accuracy: 0.583 total accuracy: 0.506 avg loss: 1.943\n",
      "[Epoch 2, Batch 640] loss: 0.868  accuracy: 0.517 total accuracy: 0.506 avg loss: 1.939\n",
      "[Epoch 2, Batch 650] loss: 0.960  accuracy: 0.383 total accuracy: 0.504 avg loss: 1.939\n",
      "[Epoch 2, Batch 660] loss: 0.910  accuracy: 0.583 total accuracy: 0.505 avg loss: 1.937\n",
      "[Epoch 2, Batch 670] loss: 1.034  accuracy: 0.500 total accuracy: 0.505 avg loss: 1.939\n",
      "[Epoch 2, Batch 680] loss: 1.144  accuracy: 0.350 total accuracy: 0.503 avg loss: 1.944\n",
      "[Epoch 2, Batch 690] loss: 1.046  accuracy: 0.483 total accuracy: 0.502 avg loss: 1.947\n",
      "[Epoch 2, Batch 700] loss: 1.068  accuracy: 0.483 total accuracy: 0.502 avg loss: 1.949\n",
      "[Epoch 2, Batch 710] loss: 0.986  accuracy: 0.567 total accuracy: 0.503 avg loss: 1.950\n",
      "[Epoch 2, Batch 720] loss: 0.929  accuracy: 0.550 total accuracy: 0.504 avg loss: 1.948\n",
      "[Epoch 2, Batch 730] loss: 1.037  accuracy: 0.500 total accuracy: 0.504 avg loss: 1.950\n",
      "[Epoch 2, Batch 740] loss: 0.925  accuracy: 0.600 total accuracy: 0.505 avg loss: 1.949\n",
      "[Epoch 2, Batch 750] loss: 1.012  accuracy: 0.483 total accuracy: 0.505 avg loss: 1.950\n",
      "[Epoch 2, Batch 760] loss: 0.915  accuracy: 0.550 total accuracy: 0.505 avg loss: 1.948\n",
      "[Epoch 2, Batch 770] loss: 1.087  accuracy: 0.467 total accuracy: 0.505 avg loss: 1.951\n",
      "[Epoch 2, Batch 780] loss: 1.138  accuracy: 0.417 total accuracy: 0.504 avg loss: 1.955\n",
      "[Epoch 2, Batch 790] loss: 1.053  accuracy: 0.400 total accuracy: 0.502 avg loss: 1.957\n",
      "[Epoch 2, Batch 800] loss: 0.868  accuracy: 0.483 total accuracy: 0.502 avg loss: 1.954\n",
      "[Epoch 2, Batch 810] loss: 1.012  accuracy: 0.400 total accuracy: 0.501 avg loss: 1.955\n",
      "[Epoch 2, Batch 820] loss: 0.836  accuracy: 0.550 total accuracy: 0.501 avg loss: 1.952\n",
      "[Epoch 2, Batch 830] loss: 1.030  accuracy: 0.467 total accuracy: 0.501 avg loss: 1.953\n",
      "[Epoch 2, Batch 840] loss: 0.911  accuracy: 0.550 total accuracy: 0.502 avg loss: 1.951\n",
      "[Epoch 2, Batch 850] loss: 0.890  accuracy: 0.617 total accuracy: 0.503 avg loss: 1.949\n",
      "[Epoch 2, Batch 860] loss: 1.040  accuracy: 0.517 total accuracy: 0.503 avg loss: 1.951\n",
      "[Epoch 2, Batch 870] loss: 0.975  accuracy: 0.483 total accuracy: 0.503 avg loss: 1.951\n",
      "[Epoch 2, Batch 880] loss: 0.945  accuracy: 0.533 total accuracy: 0.503 avg loss: 1.950\n",
      "[Epoch 2, Batch 890] loss: 0.901  accuracy: 0.517 total accuracy: 0.503 avg loss: 1.949\n",
      "[Epoch 2, Batch 900] loss: 0.963  accuracy: 0.367 total accuracy: 0.502 avg loss: 1.948\n",
      "[Epoch 2, Batch 910] loss: 0.963  accuracy: 0.433 total accuracy: 0.501 avg loss: 1.948\n",
      "[Epoch 2, Batch 920] loss: 0.855  accuracy: 0.600 total accuracy: 0.502 avg loss: 1.945\n",
      "[Epoch 2, Batch 930] loss: 1.004  accuracy: 0.467 total accuracy: 0.502 avg loss: 1.946\n",
      "[Epoch 2, Batch 940] loss: 0.972  accuracy: 0.533 total accuracy: 0.502 avg loss: 1.946\n",
      "[Epoch 2, Batch 950] loss: 0.982  accuracy: 0.467 total accuracy: 0.502 avg loss: 1.946\n",
      "[Epoch 2, Batch 960] loss: 0.931  accuracy: 0.517 total accuracy: 0.502 avg loss: 1.945\n",
      "[Epoch 2, Batch 970] loss: 0.938  accuracy: 0.417 total accuracy: 0.501 avg loss: 1.945\n",
      "Epoch 2 completed in 1059.87 seconds\n",
      "Validation loss after epoch 2: 1.897  accuracy: 0.531\n",
      "[Epoch 3, Batch 10] loss: 0.963  accuracy: 0.500 total accuracy: 0.500 avg loss: 1.926\n",
      "[Epoch 3, Batch 20] loss: 0.822  accuracy: 0.550 total accuracy: 0.525 avg loss: 1.785\n",
      "[Epoch 3, Batch 30] loss: 0.767  accuracy: 0.617 total accuracy: 0.556 avg loss: 1.702\n",
      "[Epoch 3, Batch 40] loss: 0.885  accuracy: 0.583 total accuracy: 0.562 avg loss: 1.718\n",
      "[Epoch 3, Batch 50] loss: 0.962  accuracy: 0.500 total accuracy: 0.550 avg loss: 1.760\n",
      "[Epoch 3, Batch 60] loss: 1.048  accuracy: 0.367 total accuracy: 0.519 avg loss: 1.816\n",
      "[Epoch 3, Batch 70] loss: 1.076  accuracy: 0.450 total accuracy: 0.510 avg loss: 1.864\n",
      "[Epoch 3, Batch 80] loss: 0.872  accuracy: 0.567 total accuracy: 0.517 avg loss: 1.849\n",
      "[Epoch 3, Batch 90] loss: 1.007  accuracy: 0.467 total accuracy: 0.511 avg loss: 1.867\n",
      "[Epoch 3, Batch 100] loss: 1.003  accuracy: 0.450 total accuracy: 0.505 avg loss: 1.881\n",
      "[Epoch 3, Batch 110] loss: 1.078  accuracy: 0.467 total accuracy: 0.502 avg loss: 1.906\n",
      "[Epoch 3, Batch 120] loss: 0.990  accuracy: 0.433 total accuracy: 0.496 avg loss: 1.912\n",
      "[Epoch 3, Batch 130] loss: 0.965  accuracy: 0.467 total accuracy: 0.494 avg loss: 1.914\n",
      "[Epoch 3, Batch 140] loss: 0.963  accuracy: 0.433 total accuracy: 0.489 avg loss: 1.915\n",
      "[Epoch 3, Batch 150] loss: 0.886  accuracy: 0.333 total accuracy: 0.479 avg loss: 1.905\n",
      "[Epoch 3, Batch 160] loss: 0.920  accuracy: 0.450 total accuracy: 0.477 avg loss: 1.901\n",
      "[Epoch 3, Batch 170] loss: 0.794  accuracy: 0.583 total accuracy: 0.483 avg loss: 1.883\n",
      "[Epoch 3, Batch 180] loss: 0.978  accuracy: 0.583 total accuracy: 0.489 avg loss: 1.887\n",
      "[Epoch 3, Batch 190] loss: 1.025  accuracy: 0.367 total accuracy: 0.482 avg loss: 1.895\n",
      "[Epoch 3, Batch 200] loss: 0.912  accuracy: 0.550 total accuracy: 0.486 avg loss: 1.892\n",
      "[Epoch 3, Batch 210] loss: 1.012  accuracy: 0.467 total accuracy: 0.485 avg loss: 1.898\n",
      "[Epoch 3, Batch 220] loss: 0.992  accuracy: 0.417 total accuracy: 0.482 avg loss: 1.902\n",
      "[Epoch 3, Batch 230] loss: 0.927  accuracy: 0.550 total accuracy: 0.485 avg loss: 1.900\n",
      "[Epoch 3, Batch 240] loss: 0.940  accuracy: 0.567 total accuracy: 0.488 avg loss: 1.899\n",
      "[Epoch 3, Batch 250] loss: 1.052  accuracy: 0.433 total accuracy: 0.486 avg loss: 1.907\n",
      "[Epoch 3, Batch 260] loss: 0.932  accuracy: 0.450 total accuracy: 0.485 avg loss: 1.906\n",
      "[Epoch 3, Batch 270] loss: 0.982  accuracy: 0.500 total accuracy: 0.485 avg loss: 1.908\n",
      "[Epoch 3, Batch 280] loss: 0.931  accuracy: 0.550 total accuracy: 0.487 avg loss: 1.906\n",
      "[Epoch 3, Batch 290] loss: 0.957  accuracy: 0.533 total accuracy: 0.489 avg loss: 1.906\n",
      "[Epoch 3, Batch 300] loss: 0.984  accuracy: 0.533 total accuracy: 0.491 avg loss: 1.908\n",
      "[Epoch 3, Batch 310] loss: 0.949  accuracy: 0.517 total accuracy: 0.491 avg loss: 1.908\n",
      "[Epoch 3, Batch 320] loss: 1.043  accuracy: 0.517 total accuracy: 0.492 avg loss: 1.914\n",
      "[Epoch 3, Batch 330] loss: 0.950  accuracy: 0.517 total accuracy: 0.493 avg loss: 1.913\n",
      "[Epoch 3, Batch 340] loss: 0.962  accuracy: 0.483 total accuracy: 0.493 avg loss: 1.914\n",
      "[Epoch 3, Batch 350] loss: 0.898  accuracy: 0.617 total accuracy: 0.496 avg loss: 1.910\n",
      "[Epoch 3, Batch 360] loss: 0.991  accuracy: 0.567 total accuracy: 0.498 avg loss: 1.912\n",
      "[Epoch 3, Batch 370] loss: 0.853  accuracy: 0.633 total accuracy: 0.502 avg loss: 1.907\n",
      "[Epoch 3, Batch 380] loss: 1.040  accuracy: 0.433 total accuracy: 0.500 avg loss: 1.911\n",
      "[Epoch 3, Batch 390] loss: 0.954  accuracy: 0.417 total accuracy: 0.498 avg loss: 1.911\n",
      "[Epoch 3, Batch 400] loss: 1.013  accuracy: 0.417 total accuracy: 0.496 avg loss: 1.914\n",
      "[Epoch 3, Batch 410] loss: 0.927  accuracy: 0.517 total accuracy: 0.496 avg loss: 1.913\n",
      "[Epoch 3, Batch 420] loss: 0.901  accuracy: 0.500 total accuracy: 0.496 avg loss: 1.910\n",
      "[Epoch 3, Batch 430] loss: 0.952  accuracy: 0.517 total accuracy: 0.497 avg loss: 1.910\n",
      "[Epoch 3, Batch 440] loss: 1.006  accuracy: 0.483 total accuracy: 0.497 avg loss: 1.912\n",
      "[Epoch 3, Batch 450] loss: 0.929  accuracy: 0.533 total accuracy: 0.497 avg loss: 1.911\n",
      "[Epoch 3, Batch 460] loss: 0.942  accuracy: 0.517 total accuracy: 0.498 avg loss: 1.910\n",
      "[Epoch 3, Batch 470] loss: 0.858  accuracy: 0.633 total accuracy: 0.501 avg loss: 1.906\n",
      "[Epoch 3, Batch 480] loss: 1.027  accuracy: 0.550 total accuracy: 0.502 avg loss: 1.909\n",
      "[Epoch 3, Batch 490] loss: 0.944  accuracy: 0.500 total accuracy: 0.502 avg loss: 1.909\n",
      "[Epoch 3, Batch 500] loss: 0.989  accuracy: 0.500 total accuracy: 0.502 avg loss: 1.910\n",
      "[Epoch 3, Batch 510] loss: 0.874  accuracy: 0.633 total accuracy: 0.504 avg loss: 1.907\n",
      "[Epoch 3, Batch 520] loss: 1.000  accuracy: 0.400 total accuracy: 0.502 avg loss: 1.909\n",
      "[Epoch 3, Batch 530] loss: 0.898  accuracy: 0.533 total accuracy: 0.503 avg loss: 1.907\n",
      "[Epoch 3, Batch 540] loss: 0.931  accuracy: 0.450 total accuracy: 0.502 avg loss: 1.906\n",
      "[Epoch 3, Batch 550] loss: 0.864  accuracy: 0.450 total accuracy: 0.501 avg loss: 1.903\n",
      "[Epoch 3, Batch 560] loss: 0.944  accuracy: 0.383 total accuracy: 0.499 avg loss: 1.902\n",
      "[Epoch 3, Batch 570] loss: 0.937  accuracy: 0.417 total accuracy: 0.497 avg loss: 1.902\n",
      "[Epoch 3, Batch 580] loss: 0.835  accuracy: 0.600 total accuracy: 0.499 avg loss: 1.898\n",
      "[Epoch 3, Batch 590] loss: 1.015  accuracy: 0.483 total accuracy: 0.499 avg loss: 1.900\n",
      "[Epoch 3, Batch 600] loss: 0.851  accuracy: 0.633 total accuracy: 0.501 avg loss: 1.897\n",
      "[Epoch 3, Batch 610] loss: 0.899  accuracy: 0.467 total accuracy: 0.501 avg loss: 1.895\n",
      "[Epoch 3, Batch 620] loss: 0.862  accuracy: 0.600 total accuracy: 0.502 avg loss: 1.892\n",
      "[Epoch 3, Batch 630] loss: 0.960  accuracy: 0.500 total accuracy: 0.502 avg loss: 1.893\n",
      "[Epoch 3, Batch 640] loss: 0.976  accuracy: 0.517 total accuracy: 0.502 avg loss: 1.894\n",
      "[Epoch 3, Batch 650] loss: 0.965  accuracy: 0.317 total accuracy: 0.499 avg loss: 1.894\n",
      "[Epoch 3, Batch 660] loss: 0.820  accuracy: 0.567 total accuracy: 0.501 avg loss: 1.890\n",
      "[Epoch 3, Batch 670] loss: 0.987  accuracy: 0.500 total accuracy: 0.500 avg loss: 1.892\n",
      "[Epoch 3, Batch 680] loss: 1.024  accuracy: 0.433 total accuracy: 0.500 avg loss: 1.894\n",
      "[Epoch 3, Batch 690] loss: 1.056  accuracy: 0.500 total accuracy: 0.500 avg loss: 1.897\n",
      "[Epoch 3, Batch 700] loss: 0.890  accuracy: 0.550 total accuracy: 0.500 avg loss: 1.896\n",
      "[Epoch 3, Batch 710] loss: 0.937  accuracy: 0.483 total accuracy: 0.500 avg loss: 1.895\n",
      "[Epoch 3, Batch 720] loss: 0.963  accuracy: 0.617 total accuracy: 0.502 avg loss: 1.896\n",
      "[Epoch 3, Batch 730] loss: 1.031  accuracy: 0.500 total accuracy: 0.502 avg loss: 1.898\n",
      "[Epoch 3, Batch 740] loss: 0.908  accuracy: 0.567 total accuracy: 0.502 avg loss: 1.897\n",
      "[Epoch 3, Batch 750] loss: 0.976  accuracy: 0.533 total accuracy: 0.503 avg loss: 1.898\n",
      "[Epoch 3, Batch 760] loss: 0.938  accuracy: 0.533 total accuracy: 0.503 avg loss: 1.897\n",
      "[Epoch 3, Batch 770] loss: 0.959  accuracy: 0.483 total accuracy: 0.503 avg loss: 1.898\n",
      "[Epoch 3, Batch 780] loss: 0.996  accuracy: 0.483 total accuracy: 0.503 avg loss: 1.899\n",
      "[Epoch 3, Batch 790] loss: 0.881  accuracy: 0.600 total accuracy: 0.504 avg loss: 1.897\n",
      "[Epoch 3, Batch 800] loss: 0.946  accuracy: 0.517 total accuracy: 0.504 avg loss: 1.897\n",
      "[Epoch 3, Batch 810] loss: 1.117  accuracy: 0.400 total accuracy: 0.503 avg loss: 1.901\n",
      "[Epoch 3, Batch 820] loss: 0.898  accuracy: 0.450 total accuracy: 0.502 avg loss: 1.900\n",
      "[Epoch 3, Batch 830] loss: 0.908  accuracy: 0.433 total accuracy: 0.501 avg loss: 1.899\n",
      "[Epoch 3, Batch 840] loss: 0.845  accuracy: 0.583 total accuracy: 0.502 avg loss: 1.896\n",
      "[Epoch 3, Batch 850] loss: 1.036  accuracy: 0.517 total accuracy: 0.503 avg loss: 1.898\n",
      "[Epoch 3, Batch 860] loss: 0.869  accuracy: 0.483 total accuracy: 0.502 avg loss: 1.897\n",
      "[Epoch 3, Batch 870] loss: 0.912  accuracy: 0.550 total accuracy: 0.503 avg loss: 1.896\n",
      "[Epoch 3, Batch 880] loss: 0.985  accuracy: 0.467 total accuracy: 0.502 avg loss: 1.897\n",
      "[Epoch 3, Batch 890] loss: 0.966  accuracy: 0.533 total accuracy: 0.503 avg loss: 1.897\n",
      "[Epoch 3, Batch 900] loss: 0.965  accuracy: 0.517 total accuracy: 0.503 avg loss: 1.897\n",
      "[Epoch 3, Batch 910] loss: 0.976  accuracy: 0.550 total accuracy: 0.503 avg loss: 1.898\n",
      "[Epoch 3, Batch 920] loss: 1.000  accuracy: 0.533 total accuracy: 0.504 avg loss: 1.899\n",
      "[Epoch 3, Batch 930] loss: 1.033  accuracy: 0.517 total accuracy: 0.504 avg loss: 1.901\n",
      "[Epoch 3, Batch 940] loss: 0.964  accuracy: 0.550 total accuracy: 0.504 avg loss: 1.901\n",
      "[Epoch 3, Batch 950] loss: 0.922  accuracy: 0.517 total accuracy: 0.505 avg loss: 1.901\n",
      "[Epoch 3, Batch 960] loss: 0.952  accuracy: 0.550 total accuracy: 0.505 avg loss: 1.901\n",
      "[Epoch 3, Batch 970] loss: 0.922  accuracy: 0.567 total accuracy: 0.506 avg loss: 1.900\n",
      "Epoch 3 completed in 1067.75 seconds\n",
      "Validation loss after epoch 3: 1.902  accuracy: 0.531\n",
      "[Epoch 4, Batch 10] loss: 0.905  accuracy: 0.567 total accuracy: 0.567 avg loss: 1.809\n",
      "[Epoch 4, Batch 20] loss: 0.967  accuracy: 0.517 total accuracy: 0.542 avg loss: 1.872\n",
      "[Epoch 4, Batch 30] loss: 0.920  accuracy: 0.633 total accuracy: 0.572 avg loss: 1.861\n",
      "[Epoch 4, Batch 40] loss: 0.982  accuracy: 0.533 total accuracy: 0.562 avg loss: 1.887\n",
      "[Epoch 4, Batch 50] loss: 0.966  accuracy: 0.500 total accuracy: 0.550 avg loss: 1.896\n",
      "[Epoch 4, Batch 60] loss: 0.976  accuracy: 0.500 total accuracy: 0.542 avg loss: 1.905\n",
      "[Epoch 4, Batch 70] loss: 0.986  accuracy: 0.500 total accuracy: 0.536 avg loss: 1.915\n",
      "[Epoch 4, Batch 80] loss: 1.050  accuracy: 0.383 total accuracy: 0.517 avg loss: 1.938\n",
      "[Epoch 4, Batch 90] loss: 0.997  accuracy: 0.367 total accuracy: 0.500 avg loss: 1.944\n",
      "[Epoch 4, Batch 100] loss: 0.943  accuracy: 0.417 total accuracy: 0.492 avg loss: 1.939\n",
      "[Epoch 4, Batch 110] loss: 0.917  accuracy: 0.633 total accuracy: 0.505 avg loss: 1.929\n",
      "[Epoch 4, Batch 120] loss: 0.940  accuracy: 0.533 total accuracy: 0.507 avg loss: 1.925\n",
      "[Epoch 4, Batch 130] loss: 0.926  accuracy: 0.600 total accuracy: 0.514 avg loss: 1.919\n",
      "[Epoch 4, Batch 140] loss: 0.940  accuracy: 0.533 total accuracy: 0.515 avg loss: 1.917\n",
      "[Epoch 4, Batch 150] loss: 0.924  accuracy: 0.467 total accuracy: 0.512 avg loss: 1.912\n",
      "[Epoch 4, Batch 160] loss: 0.936  accuracy: 0.550 total accuracy: 0.515 avg loss: 1.910\n",
      "[Epoch 4, Batch 170] loss: 0.992  accuracy: 0.517 total accuracy: 0.515 avg loss: 1.914\n",
      "[Epoch 4, Batch 180] loss: 0.873  accuracy: 0.533 total accuracy: 0.516 avg loss: 1.905\n",
      "[Epoch 4, Batch 190] loss: 0.972  accuracy: 0.500 total accuracy: 0.515 avg loss: 1.907\n",
      "[Epoch 4, Batch 200] loss: 0.875  accuracy: 0.583 total accuracy: 0.518 avg loss: 1.899\n",
      "[Epoch 4, Batch 210] loss: 0.891  accuracy: 0.583 total accuracy: 0.521 avg loss: 1.893\n",
      "[Epoch 4, Batch 220] loss: 0.836  accuracy: 0.633 total accuracy: 0.527 avg loss: 1.883\n",
      "[Epoch 4, Batch 230] loss: 1.035  accuracy: 0.417 total accuracy: 0.522 avg loss: 1.891\n",
      "[Epoch 4, Batch 240] loss: 0.942  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.891\n",
      "[Epoch 4, Batch 250] loss: 0.872  accuracy: 0.517 total accuracy: 0.521 avg loss: 1.885\n",
      "[Epoch 4, Batch 260] loss: 1.024  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.891\n",
      "[Epoch 4, Batch 270] loss: 0.912  accuracy: 0.467 total accuracy: 0.519 avg loss: 1.889\n",
      "[Epoch 4, Batch 280] loss: 0.911  accuracy: 0.383 total accuracy: 0.514 avg loss: 1.886\n",
      "[Epoch 4, Batch 290] loss: 0.966  accuracy: 0.350 total accuracy: 0.509 avg loss: 1.888\n",
      "[Epoch 4, Batch 300] loss: 0.992  accuracy: 0.533 total accuracy: 0.509 avg loss: 1.891\n",
      "[Epoch 4, Batch 310] loss: 0.979  accuracy: 0.500 total accuracy: 0.509 avg loss: 1.893\n",
      "[Epoch 4, Batch 320] loss: 0.835  accuracy: 0.583 total accuracy: 0.511 avg loss: 1.886\n",
      "[Epoch 4, Batch 330] loss: 0.824  accuracy: 0.583 total accuracy: 0.514 avg loss: 1.879\n",
      "[Epoch 4, Batch 340] loss: 1.018  accuracy: 0.433 total accuracy: 0.511 avg loss: 1.884\n",
      "[Epoch 4, Batch 350] loss: 0.914  accuracy: 0.550 total accuracy: 0.512 avg loss: 1.882\n",
      "[Epoch 4, Batch 360] loss: 0.901  accuracy: 0.600 total accuracy: 0.515 avg loss: 1.880\n",
      "[Epoch 4, Batch 370] loss: 0.963  accuracy: 0.533 total accuracy: 0.515 avg loss: 1.881\n",
      "[Epoch 4, Batch 380] loss: 0.958  accuracy: 0.450 total accuracy: 0.514 avg loss: 1.882\n",
      "[Epoch 4, Batch 390] loss: 0.866  accuracy: 0.533 total accuracy: 0.514 avg loss: 1.878\n",
      "[Epoch 4, Batch 400] loss: 0.934  accuracy: 0.567 total accuracy: 0.515 avg loss: 1.878\n",
      "[Epoch 4, Batch 410] loss: 0.893  accuracy: 0.500 total accuracy: 0.515 avg loss: 1.876\n",
      "[Epoch 4, Batch 420] loss: 0.841  accuracy: 0.583 total accuracy: 0.517 avg loss: 1.871\n",
      "[Epoch 4, Batch 430] loss: 1.003  accuracy: 0.433 total accuracy: 0.515 avg loss: 1.874\n",
      "[Epoch 4, Batch 440] loss: 0.909  accuracy: 0.600 total accuracy: 0.517 avg loss: 1.873\n",
      "[Epoch 4, Batch 450] loss: 0.948  accuracy: 0.567 total accuracy: 0.518 avg loss: 1.874\n",
      "[Epoch 4, Batch 460] loss: 0.938  accuracy: 0.517 total accuracy: 0.518 avg loss: 1.874\n",
      "[Epoch 4, Batch 470] loss: 0.978  accuracy: 0.467 total accuracy: 0.517 avg loss: 1.875\n",
      "[Epoch 4, Batch 480] loss: 0.923  accuracy: 0.500 total accuracy: 0.516 avg loss: 1.875\n",
      "[Epoch 4, Batch 490] loss: 0.873  accuracy: 0.483 total accuracy: 0.516 avg loss: 1.872\n",
      "[Epoch 4, Batch 500] loss: 0.890  accuracy: 0.550 total accuracy: 0.516 avg loss: 1.870\n",
      "[Epoch 4, Batch 510] loss: 0.893  accuracy: 0.517 total accuracy: 0.516 avg loss: 1.869\n",
      "[Epoch 4, Batch 520] loss: 0.923  accuracy: 0.600 total accuracy: 0.518 avg loss: 1.868\n",
      "[Epoch 4, Batch 530] loss: 1.016  accuracy: 0.467 total accuracy: 0.517 avg loss: 1.871\n",
      "[Epoch 4, Batch 540] loss: 0.933  accuracy: 0.433 total accuracy: 0.515 avg loss: 1.871\n",
      "[Epoch 4, Batch 550] loss: 0.958  accuracy: 0.500 total accuracy: 0.515 avg loss: 1.872\n",
      "[Epoch 4, Batch 560] loss: 0.977  accuracy: 0.483 total accuracy: 0.515 avg loss: 1.873\n",
      "[Epoch 4, Batch 570] loss: 0.897  accuracy: 0.550 total accuracy: 0.515 avg loss: 1.872\n",
      "[Epoch 4, Batch 580] loss: 1.085  accuracy: 0.433 total accuracy: 0.514 avg loss: 1.877\n",
      "[Epoch 4, Batch 590] loss: 0.927  accuracy: 0.533 total accuracy: 0.514 avg loss: 1.877\n",
      "[Epoch 4, Batch 600] loss: 0.929  accuracy: 0.517 total accuracy: 0.514 avg loss: 1.876\n",
      "[Epoch 4, Batch 610] loss: 0.900  accuracy: 0.433 total accuracy: 0.513 avg loss: 1.875\n",
      "[Epoch 4, Batch 620] loss: 0.847  accuracy: 0.633 total accuracy: 0.515 avg loss: 1.872\n",
      "[Epoch 4, Batch 630] loss: 1.097  accuracy: 0.500 total accuracy: 0.515 avg loss: 1.877\n",
      "[Epoch 4, Batch 640] loss: 0.996  accuracy: 0.533 total accuracy: 0.515 avg loss: 1.879\n",
      "[Epoch 4, Batch 650] loss: 0.896  accuracy: 0.550 total accuracy: 0.515 avg loss: 1.878\n",
      "[Epoch 4, Batch 660] loss: 0.898  accuracy: 0.533 total accuracy: 0.516 avg loss: 1.877\n",
      "[Epoch 4, Batch 670] loss: 0.910  accuracy: 0.500 total accuracy: 0.515 avg loss: 1.876\n",
      "[Epoch 4, Batch 680] loss: 0.955  accuracy: 0.583 total accuracy: 0.516 avg loss: 1.876\n",
      "[Epoch 4, Batch 690] loss: 1.006  accuracy: 0.567 total accuracy: 0.517 avg loss: 1.878\n",
      "[Epoch 4, Batch 700] loss: 0.983  accuracy: 0.500 total accuracy: 0.517 avg loss: 1.879\n",
      "[Epoch 4, Batch 710] loss: 0.914  accuracy: 0.550 total accuracy: 0.517 avg loss: 1.879\n",
      "[Epoch 4, Batch 720] loss: 0.949  accuracy: 0.517 total accuracy: 0.517 avg loss: 1.879\n",
      "[Epoch 4, Batch 730] loss: 0.967  accuracy: 0.600 total accuracy: 0.518 avg loss: 1.880\n",
      "[Epoch 4, Batch 740] loss: 0.886  accuracy: 0.600 total accuracy: 0.520 avg loss: 1.878\n",
      "[Epoch 4, Batch 750] loss: 1.147  accuracy: 0.383 total accuracy: 0.518 avg loss: 1.884\n",
      "[Epoch 4, Batch 760] loss: 0.941  accuracy: 0.500 total accuracy: 0.518 avg loss: 1.884\n",
      "[Epoch 4, Batch 770] loss: 1.009  accuracy: 0.483 total accuracy: 0.517 avg loss: 1.886\n",
      "[Epoch 4, Batch 780] loss: 0.955  accuracy: 0.583 total accuracy: 0.518 avg loss: 1.886\n",
      "[Epoch 4, Batch 790] loss: 0.969  accuracy: 0.450 total accuracy: 0.517 avg loss: 1.887\n",
      "[Epoch 4, Batch 800] loss: 0.953  accuracy: 0.550 total accuracy: 0.517 avg loss: 1.887\n",
      "[Epoch 4, Batch 810] loss: 0.928  accuracy: 0.650 total accuracy: 0.519 avg loss: 1.886\n",
      "[Epoch 4, Batch 820] loss: 1.020  accuracy: 0.417 total accuracy: 0.518 avg loss: 1.888\n",
      "[Epoch 4, Batch 830] loss: 0.993  accuracy: 0.483 total accuracy: 0.517 avg loss: 1.889\n",
      "[Epoch 4, Batch 840] loss: 0.899  accuracy: 0.550 total accuracy: 0.518 avg loss: 1.888\n",
      "[Epoch 4, Batch 850] loss: 0.924  accuracy: 0.500 total accuracy: 0.518 avg loss: 1.888\n",
      "[Epoch 4, Batch 860] loss: 0.844  accuracy: 0.483 total accuracy: 0.517 avg loss: 1.886\n",
      "[Epoch 4, Batch 870] loss: 0.926  accuracy: 0.467 total accuracy: 0.517 avg loss: 1.885\n",
      "[Epoch 4, Batch 880] loss: 0.857  accuracy: 0.600 total accuracy: 0.518 avg loss: 1.883\n",
      "[Epoch 4, Batch 890] loss: 1.026  accuracy: 0.517 total accuracy: 0.518 avg loss: 1.885\n",
      "[Epoch 4, Batch 900] loss: 0.863  accuracy: 0.617 total accuracy: 0.519 avg loss: 1.883\n",
      "[Epoch 4, Batch 910] loss: 1.114  accuracy: 0.383 total accuracy: 0.517 avg loss: 1.887\n",
      "[Epoch 4, Batch 920] loss: 0.912  accuracy: 0.667 total accuracy: 0.519 avg loss: 1.886\n",
      "[Epoch 4, Batch 930] loss: 0.945  accuracy: 0.517 total accuracy: 0.519 avg loss: 1.887\n",
      "[Epoch 4, Batch 940] loss: 0.945  accuracy: 0.483 total accuracy: 0.518 avg loss: 1.887\n",
      "[Epoch 4, Batch 950] loss: 1.027  accuracy: 0.450 total accuracy: 0.518 avg loss: 1.888\n",
      "[Epoch 4, Batch 960] loss: 0.900  accuracy: 0.550 total accuracy: 0.518 avg loss: 1.887\n",
      "[Epoch 4, Batch 970] loss: 1.040  accuracy: 0.450 total accuracy: 0.517 avg loss: 1.889\n",
      "Epoch 4 completed in 1080.44 seconds\n",
      "Validation loss after epoch 4: 1.957  accuracy: 0.364\n",
      "[Epoch 5, Batch 10] loss: 0.872  accuracy: 0.533 total accuracy: 0.533 avg loss: 1.745\n",
      "[Epoch 5, Batch 20] loss: 0.924  accuracy: 0.567 total accuracy: 0.550 avg loss: 1.797\n",
      "[Epoch 5, Batch 30] loss: 0.944  accuracy: 0.567 total accuracy: 0.556 avg loss: 1.827\n",
      "[Epoch 5, Batch 40] loss: 0.937  accuracy: 0.483 total accuracy: 0.537 avg loss: 1.839\n",
      "[Epoch 5, Batch 50] loss: 0.923  accuracy: 0.550 total accuracy: 0.540 avg loss: 1.840\n",
      "[Epoch 5, Batch 60] loss: 0.896  accuracy: 0.617 total accuracy: 0.553 avg loss: 1.832\n",
      "[Epoch 5, Batch 70] loss: 1.040  accuracy: 0.483 total accuracy: 0.543 avg loss: 1.868\n",
      "[Epoch 5, Batch 80] loss: 0.800  accuracy: 0.700 total accuracy: 0.562 avg loss: 1.834\n",
      "[Epoch 5, Batch 90] loss: 0.967  accuracy: 0.533 total accuracy: 0.559 avg loss: 1.845\n",
      "[Epoch 5, Batch 100] loss: 0.875  accuracy: 0.583 total accuracy: 0.562 avg loss: 1.836\n",
      "[Epoch 5, Batch 110] loss: 0.951  accuracy: 0.550 total accuracy: 0.561 avg loss: 1.842\n",
      "[Epoch 5, Batch 120] loss: 0.879  accuracy: 0.567 total accuracy: 0.561 avg loss: 1.835\n",
      "[Epoch 5, Batch 130] loss: 0.960  accuracy: 0.583 total accuracy: 0.563 avg loss: 1.841\n",
      "[Epoch 5, Batch 140] loss: 0.883  accuracy: 0.517 total accuracy: 0.560 avg loss: 1.836\n",
      "[Epoch 5, Batch 150] loss: 0.994  accuracy: 0.500 total accuracy: 0.556 avg loss: 1.846\n",
      "[Epoch 5, Batch 160] loss: 1.057  accuracy: 0.400 total accuracy: 0.546 avg loss: 1.863\n",
      "[Epoch 5, Batch 170] loss: 0.950  accuracy: 0.433 total accuracy: 0.539 avg loss: 1.865\n",
      "[Epoch 5, Batch 180] loss: 1.060  accuracy: 0.350 total accuracy: 0.529 avg loss: 1.879\n",
      "[Epoch 5, Batch 190] loss: 0.946  accuracy: 0.467 total accuracy: 0.525 avg loss: 1.880\n",
      "[Epoch 5, Batch 200] loss: 0.920  accuracy: 0.467 total accuracy: 0.522 avg loss: 1.878\n",
      "[Epoch 5, Batch 210] loss: 1.013  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.885\n",
      "[Epoch 5, Batch 220] loss: 1.064  accuracy: 0.417 total accuracy: 0.517 avg loss: 1.896\n",
      "[Epoch 5, Batch 230] loss: 0.902  accuracy: 0.567 total accuracy: 0.519 avg loss: 1.892\n",
      "[Epoch 5, Batch 240] loss: 0.963  accuracy: 0.517 total accuracy: 0.519 avg loss: 1.894\n",
      "[Epoch 5, Batch 250] loss: 0.956  accuracy: 0.533 total accuracy: 0.519 avg loss: 1.894\n",
      "[Epoch 5, Batch 260] loss: 0.975  accuracy: 0.533 total accuracy: 0.520 avg loss: 1.896\n",
      "[Epoch 5, Batch 270] loss: 0.908  accuracy: 0.600 total accuracy: 0.523 avg loss: 1.893\n",
      "[Epoch 5, Batch 280] loss: 0.879  accuracy: 0.550 total accuracy: 0.524 avg loss: 1.889\n",
      "[Epoch 5, Batch 290] loss: 0.964  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.890\n",
      "[Epoch 5, Batch 300] loss: 0.835  accuracy: 0.567 total accuracy: 0.524 avg loss: 1.883\n",
      "[Epoch 5, Batch 310] loss: 1.017  accuracy: 0.467 total accuracy: 0.522 avg loss: 1.887\n",
      "[Epoch 5, Batch 320] loss: 1.048  accuracy: 0.483 total accuracy: 0.521 avg loss: 1.894\n",
      "[Epoch 5, Batch 330] loss: 0.932  accuracy: 0.583 total accuracy: 0.523 avg loss: 1.893\n",
      "[Epoch 5, Batch 340] loss: 0.892  accuracy: 0.567 total accuracy: 0.524 avg loss: 1.890\n",
      "[Epoch 5, Batch 350] loss: 0.938  accuracy: 0.483 total accuracy: 0.523 avg loss: 1.889\n",
      "[Epoch 5, Batch 360] loss: 0.919  accuracy: 0.517 total accuracy: 0.523 avg loss: 1.888\n",
      "[Epoch 5, Batch 370] loss: 1.111  accuracy: 0.433 total accuracy: 0.520 avg loss: 1.897\n",
      "[Epoch 5, Batch 380] loss: 0.894  accuracy: 0.550 total accuracy: 0.521 avg loss: 1.894\n",
      "[Epoch 5, Batch 390] loss: 0.958  accuracy: 0.450 total accuracy: 0.519 avg loss: 1.895\n",
      "[Epoch 5, Batch 400] loss: 0.875  accuracy: 0.500 total accuracy: 0.519 avg loss: 1.891\n",
      "[Epoch 5, Batch 410] loss: 0.886  accuracy: 0.567 total accuracy: 0.520 avg loss: 1.888\n",
      "[Epoch 5, Batch 420] loss: 0.871  accuracy: 0.483 total accuracy: 0.519 avg loss: 1.885\n",
      "[Epoch 5, Batch 430] loss: 0.959  accuracy: 0.483 total accuracy: 0.518 avg loss: 1.886\n",
      "[Epoch 5, Batch 440] loss: 1.049  accuracy: 0.433 total accuracy: 0.516 avg loss: 1.890\n",
      "[Epoch 5, Batch 450] loss: 0.919  accuracy: 0.533 total accuracy: 0.517 avg loss: 1.889\n",
      "[Epoch 5, Batch 460] loss: 0.935  accuracy: 0.550 total accuracy: 0.517 avg loss: 1.889\n",
      "[Epoch 5, Batch 470] loss: 0.878  accuracy: 0.583 total accuracy: 0.519 avg loss: 1.886\n",
      "[Epoch 5, Batch 480] loss: 1.055  accuracy: 0.467 total accuracy: 0.518 avg loss: 1.891\n",
      "[Epoch 5, Batch 490] loss: 0.928  accuracy: 0.500 total accuracy: 0.517 avg loss: 1.890\n",
      "[Epoch 5, Batch 500] loss: 0.974  accuracy: 0.550 total accuracy: 0.518 avg loss: 1.891\n",
      "[Epoch 5, Batch 510] loss: 0.867  accuracy: 0.650 total accuracy: 0.521 avg loss: 1.888\n",
      "[Epoch 5, Batch 520] loss: 0.906  accuracy: 0.517 total accuracy: 0.521 avg loss: 1.887\n",
      "[Epoch 5, Batch 530] loss: 0.987  accuracy: 0.433 total accuracy: 0.519 avg loss: 1.888\n",
      "[Epoch 5, Batch 540] loss: 0.891  accuracy: 0.517 total accuracy: 0.519 avg loss: 1.886\n",
      "[Epoch 5, Batch 550] loss: 1.038  accuracy: 0.400 total accuracy: 0.517 avg loss: 1.890\n",
      "[Epoch 5, Batch 560] loss: 0.870  accuracy: 0.517 total accuracy: 0.517 avg loss: 1.887\n",
      "[Epoch 5, Batch 570] loss: 0.925  accuracy: 0.517 total accuracy: 0.517 avg loss: 1.886\n",
      "[Epoch 5, Batch 580] loss: 0.970  accuracy: 0.550 total accuracy: 0.517 avg loss: 1.887\n",
      "[Epoch 5, Batch 590] loss: 0.844  accuracy: 0.517 total accuracy: 0.517 avg loss: 1.884\n",
      "[Epoch 5, Batch 600] loss: 0.865  accuracy: 0.600 total accuracy: 0.519 avg loss: 1.881\n",
      "[Epoch 5, Batch 610] loss: 1.026  accuracy: 0.450 total accuracy: 0.517 avg loss: 1.884\n",
      "[Epoch 5, Batch 620] loss: 0.883  accuracy: 0.550 total accuracy: 0.518 avg loss: 1.882\n",
      "[Epoch 5, Batch 630] loss: 0.925  accuracy: 0.567 total accuracy: 0.519 avg loss: 1.882\n",
      "[Epoch 5, Batch 640] loss: 0.796  accuracy: 0.700 total accuracy: 0.522 avg loss: 1.877\n",
      "[Epoch 5, Batch 650] loss: 0.948  accuracy: 0.567 total accuracy: 0.522 avg loss: 1.878\n",
      "[Epoch 5, Batch 660] loss: 0.968  accuracy: 0.500 total accuracy: 0.522 avg loss: 1.878\n",
      "[Epoch 5, Batch 670] loss: 0.861  accuracy: 0.517 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 5, Batch 680] loss: 0.937  accuracy: 0.533 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 5, Batch 690] loss: 0.984  accuracy: 0.450 total accuracy: 0.521 avg loss: 1.877\n",
      "[Epoch 5, Batch 700] loss: 0.864  accuracy: 0.650 total accuracy: 0.523 avg loss: 1.875\n",
      "[Epoch 5, Batch 710] loss: 0.967  accuracy: 0.517 total accuracy: 0.523 avg loss: 1.876\n",
      "[Epoch 5, Batch 720] loss: 0.913  accuracy: 0.583 total accuracy: 0.524 avg loss: 1.875\n",
      "[Epoch 5, Batch 730] loss: 0.984  accuracy: 0.517 total accuracy: 0.524 avg loss: 1.877\n",
      "[Epoch 5, Batch 740] loss: 0.893  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.875\n",
      "[Epoch 5, Batch 750] loss: 0.855  accuracy: 0.517 total accuracy: 0.523 avg loss: 1.873\n",
      "[Epoch 5, Batch 760] loss: 0.900  accuracy: 0.583 total accuracy: 0.524 avg loss: 1.872\n",
      "[Epoch 5, Batch 770] loss: 0.852  accuracy: 0.633 total accuracy: 0.525 avg loss: 1.870\n",
      "[Epoch 5, Batch 780] loss: 1.096  accuracy: 0.517 total accuracy: 0.525 avg loss: 1.874\n",
      "[Epoch 5, Batch 790] loss: 0.963  accuracy: 0.483 total accuracy: 0.525 avg loss: 1.875\n",
      "[Epoch 5, Batch 800] loss: 0.966  accuracy: 0.450 total accuracy: 0.524 avg loss: 1.876\n",
      "[Epoch 5, Batch 810] loss: 1.041  accuracy: 0.433 total accuracy: 0.523 avg loss: 1.878\n",
      "[Epoch 5, Batch 820] loss: 0.940  accuracy: 0.350 total accuracy: 0.521 avg loss: 1.878\n",
      "[Epoch 5, Batch 830] loss: 0.999  accuracy: 0.433 total accuracy: 0.519 avg loss: 1.880\n",
      "[Epoch 5, Batch 840] loss: 0.900  accuracy: 0.600 total accuracy: 0.520 avg loss: 1.879\n",
      "[Epoch 5, Batch 850] loss: 0.972  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.879\n",
      "[Epoch 5, Batch 860] loss: 0.847  accuracy: 0.483 total accuracy: 0.520 avg loss: 1.877\n",
      "[Epoch 5, Batch 870] loss: 0.964  accuracy: 0.350 total accuracy: 0.518 avg loss: 1.878\n",
      "[Epoch 5, Batch 880] loss: 0.849  accuracy: 0.633 total accuracy: 0.520 avg loss: 1.876\n",
      "[Epoch 5, Batch 890] loss: 0.963  accuracy: 0.483 total accuracy: 0.519 avg loss: 1.876\n",
      "[Epoch 5, Batch 900] loss: 0.984  accuracy: 0.467 total accuracy: 0.519 avg loss: 1.877\n",
      "[Epoch 5, Batch 910] loss: 0.993  accuracy: 0.483 total accuracy: 0.518 avg loss: 1.879\n",
      "[Epoch 5, Batch 920] loss: 0.873  accuracy: 0.650 total accuracy: 0.520 avg loss: 1.877\n",
      "[Epoch 5, Batch 930] loss: 1.045  accuracy: 0.467 total accuracy: 0.519 avg loss: 1.879\n",
      "[Epoch 5, Batch 940] loss: 0.940  accuracy: 0.567 total accuracy: 0.520 avg loss: 1.879\n",
      "[Epoch 5, Batch 950] loss: 0.976  accuracy: 0.467 total accuracy: 0.519 avg loss: 1.880\n",
      "[Epoch 5, Batch 960] loss: 0.849  accuracy: 0.533 total accuracy: 0.519 avg loss: 1.878\n",
      "[Epoch 5, Batch 970] loss: 1.086  accuracy: 0.450 total accuracy: 0.518 avg loss: 1.881\n",
      "Epoch 5 completed in 1084.11 seconds\n",
      "Validation loss after epoch 5: 1.886  accuracy: 0.531\n",
      "[Epoch 6, Batch 10] loss: 0.949  accuracy: 0.500 total accuracy: 0.500 avg loss: 1.898\n",
      "[Epoch 6, Batch 20] loss: 0.893  accuracy: 0.533 total accuracy: 0.517 avg loss: 1.842\n",
      "[Epoch 6, Batch 30] loss: 1.018  accuracy: 0.367 total accuracy: 0.467 avg loss: 1.907\n",
      "[Epoch 6, Batch 40] loss: 0.992  accuracy: 0.500 total accuracy: 0.475 avg loss: 1.926\n",
      "[Epoch 6, Batch 50] loss: 0.945  accuracy: 0.533 total accuracy: 0.487 avg loss: 1.919\n",
      "[Epoch 6, Batch 60] loss: 0.941  accuracy: 0.367 total accuracy: 0.467 avg loss: 1.913\n",
      "[Epoch 6, Batch 70] loss: 0.927  accuracy: 0.400 total accuracy: 0.457 avg loss: 1.905\n",
      "[Epoch 6, Batch 80] loss: 0.868  accuracy: 0.550 total accuracy: 0.469 avg loss: 1.883\n",
      "[Epoch 6, Batch 90] loss: 0.959  accuracy: 0.450 total accuracy: 0.467 avg loss: 1.887\n",
      "[Epoch 6, Batch 100] loss: 0.882  accuracy: 0.550 total accuracy: 0.475 avg loss: 1.875\n",
      "[Epoch 6, Batch 110] loss: 0.993  accuracy: 0.517 total accuracy: 0.479 avg loss: 1.885\n",
      "[Epoch 6, Batch 120] loss: 0.892  accuracy: 0.533 total accuracy: 0.483 avg loss: 1.877\n",
      "[Epoch 6, Batch 130] loss: 1.000  accuracy: 0.400 total accuracy: 0.477 avg loss: 1.886\n",
      "[Epoch 6, Batch 140] loss: 1.017  accuracy: 0.500 total accuracy: 0.479 avg loss: 1.897\n",
      "[Epoch 6, Batch 150] loss: 0.973  accuracy: 0.533 total accuracy: 0.482 avg loss: 1.900\n",
      "[Epoch 6, Batch 160] loss: 0.982  accuracy: 0.567 total accuracy: 0.487 avg loss: 1.904\n",
      "[Epoch 6, Batch 170] loss: 0.925  accuracy: 0.533 total accuracy: 0.490 avg loss: 1.901\n",
      "[Epoch 6, Batch 180] loss: 1.000  accuracy: 0.517 total accuracy: 0.492 avg loss: 1.906\n",
      "[Epoch 6, Batch 190] loss: 0.809  accuracy: 0.650 total accuracy: 0.500 avg loss: 1.891\n",
      "[Epoch 6, Batch 200] loss: 0.898  accuracy: 0.533 total accuracy: 0.502 avg loss: 1.886\n",
      "[Epoch 6, Batch 210] loss: 0.936  accuracy: 0.533 total accuracy: 0.503 avg loss: 1.886\n",
      "[Epoch 6, Batch 220] loss: 0.807  accuracy: 0.667 total accuracy: 0.511 avg loss: 1.873\n",
      "[Epoch 6, Batch 230] loss: 0.943  accuracy: 0.617 total accuracy: 0.515 avg loss: 1.874\n",
      "[Epoch 6, Batch 240] loss: 0.956  accuracy: 0.550 total accuracy: 0.517 avg loss: 1.876\n",
      "[Epoch 6, Batch 250] loss: 1.091  accuracy: 0.433 total accuracy: 0.513 avg loss: 1.888\n",
      "[Epoch 6, Batch 260] loss: 0.901  accuracy: 0.400 total accuracy: 0.509 avg loss: 1.884\n",
      "[Epoch 6, Batch 270] loss: 0.933  accuracy: 0.533 total accuracy: 0.510 avg loss: 1.884\n",
      "[Epoch 6, Batch 280] loss: 0.926  accuracy: 0.517 total accuracy: 0.510 avg loss: 1.883\n",
      "[Epoch 6, Batch 290] loss: 0.875  accuracy: 0.533 total accuracy: 0.511 avg loss: 1.878\n",
      "[Epoch 6, Batch 300] loss: 0.870  accuracy: 0.600 total accuracy: 0.514 avg loss: 1.873\n",
      "[Epoch 6, Batch 310] loss: 0.886  accuracy: 0.533 total accuracy: 0.515 avg loss: 1.870\n",
      "[Epoch 6, Batch 320] loss: 0.923  accuracy: 0.600 total accuracy: 0.517 avg loss: 1.869\n",
      "[Epoch 6, Batch 330] loss: 0.977  accuracy: 0.417 total accuracy: 0.514 avg loss: 1.872\n",
      "[Epoch 6, Batch 340] loss: 1.003  accuracy: 0.467 total accuracy: 0.513 avg loss: 1.876\n",
      "[Epoch 6, Batch 350] loss: 0.968  accuracy: 0.500 total accuracy: 0.512 avg loss: 1.878\n",
      "[Epoch 6, Batch 360] loss: 0.951  accuracy: 0.467 total accuracy: 0.511 avg loss: 1.878\n",
      "[Epoch 6, Batch 370] loss: 0.839  accuracy: 0.617 total accuracy: 0.514 avg loss: 1.873\n",
      "[Epoch 6, Batch 380] loss: 0.941  accuracy: 0.517 total accuracy: 0.514 avg loss: 1.873\n",
      "[Epoch 6, Batch 390] loss: 0.950  accuracy: 0.567 total accuracy: 0.515 avg loss: 1.874\n",
      "[Epoch 6, Batch 400] loss: 0.915  accuracy: 0.583 total accuracy: 0.517 avg loss: 1.873\n",
      "[Epoch 6, Batch 410] loss: 1.044  accuracy: 0.433 total accuracy: 0.515 avg loss: 1.878\n",
      "[Epoch 6, Batch 420] loss: 0.774  accuracy: 0.600 total accuracy: 0.517 avg loss: 1.870\n",
      "[Epoch 6, Batch 430] loss: 0.970  accuracy: 0.517 total accuracy: 0.517 avg loss: 1.872\n",
      "[Epoch 6, Batch 440] loss: 0.911  accuracy: 0.533 total accuracy: 0.517 avg loss: 1.871\n",
      "[Epoch 6, Batch 450] loss: 1.106  accuracy: 0.383 total accuracy: 0.514 avg loss: 1.878\n",
      "[Epoch 6, Batch 460] loss: 0.991  accuracy: 0.483 total accuracy: 0.514 avg loss: 1.881\n",
      "[Epoch 6, Batch 470] loss: 0.865  accuracy: 0.617 total accuracy: 0.516 avg loss: 1.877\n",
      "[Epoch 6, Batch 480] loss: 0.874  accuracy: 0.517 total accuracy: 0.516 avg loss: 1.875\n",
      "[Epoch 6, Batch 490] loss: 0.869  accuracy: 0.600 total accuracy: 0.518 avg loss: 1.872\n",
      "[Epoch 6, Batch 500] loss: 0.987  accuracy: 0.517 total accuracy: 0.518 avg loss: 1.874\n",
      "[Epoch 6, Batch 510] loss: 0.951  accuracy: 0.550 total accuracy: 0.518 avg loss: 1.874\n",
      "[Epoch 6, Batch 520] loss: 0.941  accuracy: 0.567 total accuracy: 0.519 avg loss: 1.875\n",
      "[Epoch 6, Batch 530] loss: 0.958  accuracy: 0.533 total accuracy: 0.519 avg loss: 1.875\n",
      "[Epoch 6, Batch 540] loss: 0.953  accuracy: 0.500 total accuracy: 0.519 avg loss: 1.876\n",
      "[Epoch 6, Batch 550] loss: 0.950  accuracy: 0.433 total accuracy: 0.518 avg loss: 1.876\n",
      "[Epoch 6, Batch 560] loss: 0.930  accuracy: 0.500 total accuracy: 0.517 avg loss: 1.876\n",
      "[Epoch 6, Batch 570] loss: 0.913  accuracy: 0.583 total accuracy: 0.518 avg loss: 1.875\n",
      "[Epoch 6, Batch 580] loss: 0.923  accuracy: 0.500 total accuracy: 0.518 avg loss: 1.875\n",
      "[Epoch 6, Batch 590] loss: 1.001  accuracy: 0.400 total accuracy: 0.516 avg loss: 1.877\n",
      "[Epoch 6, Batch 600] loss: 0.937  accuracy: 0.583 total accuracy: 0.517 avg loss: 1.877\n",
      "[Epoch 6, Batch 610] loss: 0.968  accuracy: 0.500 total accuracy: 0.517 avg loss: 1.878\n",
      "[Epoch 6, Batch 620] loss: 0.849  accuracy: 0.600 total accuracy: 0.518 avg loss: 1.875\n",
      "[Epoch 6, Batch 630] loss: 0.882  accuracy: 0.567 total accuracy: 0.519 avg loss: 1.873\n",
      "[Epoch 6, Batch 640] loss: 0.923  accuracy: 0.567 total accuracy: 0.520 avg loss: 1.873\n",
      "[Epoch 6, Batch 650] loss: 0.948  accuracy: 0.517 total accuracy: 0.520 avg loss: 1.873\n",
      "[Epoch 6, Batch 660] loss: 0.949  accuracy: 0.483 total accuracy: 0.519 avg loss: 1.873\n",
      "[Epoch 6, Batch 670] loss: 1.006  accuracy: 0.467 total accuracy: 0.518 avg loss: 1.876\n",
      "[Epoch 6, Batch 680] loss: 0.953  accuracy: 0.450 total accuracy: 0.517 avg loss: 1.876\n",
      "[Epoch 6, Batch 690] loss: 0.872  accuracy: 0.550 total accuracy: 0.518 avg loss: 1.874\n",
      "[Epoch 6, Batch 700] loss: 1.050  accuracy: 0.500 total accuracy: 0.518 avg loss: 1.877\n",
      "[Epoch 6, Batch 710] loss: 0.927  accuracy: 0.617 total accuracy: 0.519 avg loss: 1.877\n",
      "[Epoch 6, Batch 720] loss: 0.982  accuracy: 0.533 total accuracy: 0.519 avg loss: 1.878\n",
      "[Epoch 6, Batch 730] loss: 1.018  accuracy: 0.450 total accuracy: 0.518 avg loss: 1.880\n",
      "[Epoch 6, Batch 740] loss: 0.937  accuracy: 0.500 total accuracy: 0.518 avg loss: 1.880\n",
      "[Epoch 6, Batch 750] loss: 0.934  accuracy: 0.567 total accuracy: 0.519 avg loss: 1.880\n",
      "[Epoch 6, Batch 760] loss: 0.909  accuracy: 0.550 total accuracy: 0.519 avg loss: 1.879\n",
      "[Epoch 6, Batch 770] loss: 0.933  accuracy: 0.500 total accuracy: 0.519 avg loss: 1.879\n",
      "[Epoch 6, Batch 780] loss: 0.908  accuracy: 0.550 total accuracy: 0.519 avg loss: 1.878\n",
      "[Epoch 6, Batch 790] loss: 0.923  accuracy: 0.500 total accuracy: 0.519 avg loss: 1.878\n",
      "[Epoch 6, Batch 800] loss: 0.858  accuracy: 0.567 total accuracy: 0.520 avg loss: 1.876\n",
      "[Epoch 6, Batch 810] loss: 1.055  accuracy: 0.467 total accuracy: 0.519 avg loss: 1.879\n",
      "[Epoch 6, Batch 820] loss: 0.850  accuracy: 0.667 total accuracy: 0.521 avg loss: 1.877\n",
      "[Epoch 6, Batch 830] loss: 0.910  accuracy: 0.583 total accuracy: 0.521 avg loss: 1.876\n",
      "[Epoch 6, Batch 840] loss: 0.900  accuracy: 0.600 total accuracy: 0.522 avg loss: 1.875\n",
      "[Epoch 6, Batch 850] loss: 0.948  accuracy: 0.533 total accuracy: 0.523 avg loss: 1.875\n",
      "[Epoch 6, Batch 860] loss: 0.923  accuracy: 0.517 total accuracy: 0.522 avg loss: 1.875\n",
      "[Epoch 6, Batch 870] loss: 0.934  accuracy: 0.467 total accuracy: 0.522 avg loss: 1.875\n",
      "[Epoch 6, Batch 880] loss: 0.966  accuracy: 0.550 total accuracy: 0.522 avg loss: 1.875\n",
      "[Epoch 6, Batch 890] loss: 0.954  accuracy: 0.617 total accuracy: 0.523 avg loss: 1.876\n",
      "[Epoch 6, Batch 900] loss: 0.863  accuracy: 0.567 total accuracy: 0.524 avg loss: 1.874\n",
      "[Epoch 6, Batch 910] loss: 0.902  accuracy: 0.517 total accuracy: 0.524 avg loss: 1.873\n",
      "[Epoch 6, Batch 920] loss: 0.962  accuracy: 0.533 total accuracy: 0.524 avg loss: 1.874\n",
      "[Epoch 6, Batch 930] loss: 1.011  accuracy: 0.383 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 6, Batch 940] loss: 1.062  accuracy: 0.383 total accuracy: 0.521 avg loss: 1.878\n",
      "[Epoch 6, Batch 950] loss: 1.019  accuracy: 0.467 total accuracy: 0.520 avg loss: 1.880\n",
      "[Epoch 6, Batch 960] loss: 1.051  accuracy: 0.417 total accuracy: 0.519 avg loss: 1.882\n",
      "[Epoch 6, Batch 970] loss: 0.894  accuracy: 0.533 total accuracy: 0.519 avg loss: 1.881\n",
      "Epoch 6 completed in 1077.37 seconds\n",
      "Validation loss after epoch 6: 1.892  accuracy: 0.531\n",
      "[Epoch 7, Batch 10] loss: 1.029  accuracy: 0.517 total accuracy: 0.517 avg loss: 2.057\n",
      "[Epoch 7, Batch 20] loss: 0.987  accuracy: 0.500 total accuracy: 0.508 avg loss: 2.015\n",
      "[Epoch 7, Batch 30] loss: 0.874  accuracy: 0.633 total accuracy: 0.550 avg loss: 1.926\n",
      "[Epoch 7, Batch 40] loss: 0.863  accuracy: 0.600 total accuracy: 0.562 avg loss: 1.876\n",
      "[Epoch 7, Batch 50] loss: 0.884  accuracy: 0.533 total accuracy: 0.557 avg loss: 1.854\n",
      "[Epoch 7, Batch 60] loss: 0.890  accuracy: 0.600 total accuracy: 0.564 avg loss: 1.842\n",
      "[Epoch 7, Batch 70] loss: 0.868  accuracy: 0.533 total accuracy: 0.560 avg loss: 1.827\n",
      "[Epoch 7, Batch 80] loss: 0.914  accuracy: 0.483 total accuracy: 0.550 avg loss: 1.827\n",
      "[Epoch 7, Batch 90] loss: 1.012  accuracy: 0.467 total accuracy: 0.541 avg loss: 1.849\n",
      "[Epoch 7, Batch 100] loss: 0.896  accuracy: 0.550 total accuracy: 0.542 avg loss: 1.844\n",
      "[Epoch 7, Batch 110] loss: 0.897  accuracy: 0.600 total accuracy: 0.547 avg loss: 1.839\n",
      "[Epoch 7, Batch 120] loss: 0.965  accuracy: 0.600 total accuracy: 0.551 avg loss: 1.847\n",
      "[Epoch 7, Batch 130] loss: 0.857  accuracy: 0.617 total accuracy: 0.556 avg loss: 1.836\n",
      "[Epoch 7, Batch 140] loss: 0.889  accuracy: 0.600 total accuracy: 0.560 avg loss: 1.832\n",
      "[Epoch 7, Batch 150] loss: 0.881  accuracy: 0.567 total accuracy: 0.560 avg loss: 1.828\n",
      "[Epoch 7, Batch 160] loss: 1.011  accuracy: 0.483 total accuracy: 0.555 avg loss: 1.840\n",
      "[Epoch 7, Batch 170] loss: 0.913  accuracy: 0.600 total accuracy: 0.558 avg loss: 1.839\n",
      "[Epoch 7, Batch 180] loss: 0.907  accuracy: 0.550 total accuracy: 0.557 avg loss: 1.838\n",
      "[Epoch 7, Batch 190] loss: 0.884  accuracy: 0.550 total accuracy: 0.557 avg loss: 1.834\n",
      "[Epoch 7, Batch 200] loss: 0.875  accuracy: 0.567 total accuracy: 0.557 avg loss: 1.830\n",
      "[Epoch 7, Batch 210] loss: 0.896  accuracy: 0.583 total accuracy: 0.559 avg loss: 1.828\n",
      "[Epoch 7, Batch 220] loss: 1.014  accuracy: 0.483 total accuracy: 0.555 avg loss: 1.837\n",
      "[Epoch 7, Batch 230] loss: 0.936  accuracy: 0.467 total accuracy: 0.551 avg loss: 1.838\n",
      "[Epoch 7, Batch 240] loss: 0.905  accuracy: 0.567 total accuracy: 0.552 avg loss: 1.837\n",
      "[Epoch 7, Batch 250] loss: 0.938  accuracy: 0.533 total accuracy: 0.551 avg loss: 1.839\n",
      "[Epoch 7, Batch 260] loss: 0.807  accuracy: 0.467 total accuracy: 0.548 avg loss: 1.830\n",
      "[Epoch 7, Batch 270] loss: 1.011  accuracy: 0.450 total accuracy: 0.544 avg loss: 1.837\n",
      "[Epoch 7, Batch 280] loss: 0.832  accuracy: 0.550 total accuracy: 0.545 avg loss: 1.831\n",
      "[Epoch 7, Batch 290] loss: 0.974  accuracy: 0.517 total accuracy: 0.544 avg loss: 1.835\n",
      "[Epoch 7, Batch 300] loss: 1.001  accuracy: 0.500 total accuracy: 0.542 avg loss: 1.841\n",
      "[Epoch 7, Batch 310] loss: 0.958  accuracy: 0.467 total accuracy: 0.540 avg loss: 1.843\n",
      "[Epoch 7, Batch 320] loss: 0.937  accuracy: 0.533 total accuracy: 0.540 avg loss: 1.844\n",
      "[Epoch 7, Batch 330] loss: 0.815  accuracy: 0.567 total accuracy: 0.540 avg loss: 1.838\n",
      "[Epoch 7, Batch 340] loss: 1.042  accuracy: 0.417 total accuracy: 0.537 avg loss: 1.845\n",
      "[Epoch 7, Batch 350] loss: 0.948  accuracy: 0.500 total accuracy: 0.536 avg loss: 1.846\n",
      "[Epoch 7, Batch 360] loss: 0.825  accuracy: 0.700 total accuracy: 0.540 avg loss: 1.841\n",
      "[Epoch 7, Batch 370] loss: 0.943  accuracy: 0.517 total accuracy: 0.540 avg loss: 1.842\n",
      "[Epoch 7, Batch 380] loss: 1.024  accuracy: 0.450 total accuracy: 0.537 avg loss: 1.848\n",
      "[Epoch 7, Batch 390] loss: 0.897  accuracy: 0.583 total accuracy: 0.538 avg loss: 1.846\n",
      "[Epoch 7, Batch 400] loss: 0.936  accuracy: 0.533 total accuracy: 0.538 avg loss: 1.847\n",
      "[Epoch 7, Batch 410] loss: 0.921  accuracy: 0.517 total accuracy: 0.538 avg loss: 1.847\n",
      "[Epoch 7, Batch 420] loss: 0.911  accuracy: 0.600 total accuracy: 0.539 avg loss: 1.846\n",
      "[Epoch 7, Batch 430] loss: 0.994  accuracy: 0.550 total accuracy: 0.540 avg loss: 1.849\n",
      "[Epoch 7, Batch 440] loss: 0.933  accuracy: 0.500 total accuracy: 0.539 avg loss: 1.850\n",
      "[Epoch 7, Batch 450] loss: 0.873  accuracy: 0.533 total accuracy: 0.539 avg loss: 1.847\n",
      "[Epoch 7, Batch 460] loss: 0.937  accuracy: 0.583 total accuracy: 0.539 avg loss: 1.848\n",
      "[Epoch 7, Batch 470] loss: 0.884  accuracy: 0.550 total accuracy: 0.540 avg loss: 1.846\n",
      "[Epoch 7, Batch 480] loss: 0.892  accuracy: 0.583 total accuracy: 0.541 avg loss: 1.845\n",
      "[Epoch 7, Batch 490] loss: 0.961  accuracy: 0.483 total accuracy: 0.539 avg loss: 1.847\n",
      "[Epoch 7, Batch 500] loss: 0.874  accuracy: 0.567 total accuracy: 0.540 avg loss: 1.845\n",
      "[Epoch 7, Batch 510] loss: 0.986  accuracy: 0.467 total accuracy: 0.539 avg loss: 1.847\n",
      "[Epoch 7, Batch 520] loss: 0.925  accuracy: 0.483 total accuracy: 0.537 avg loss: 1.847\n",
      "[Epoch 7, Batch 530] loss: 0.927  accuracy: 0.483 total accuracy: 0.536 avg loss: 1.847\n",
      "[Epoch 7, Batch 540] loss: 1.045  accuracy: 0.483 total accuracy: 0.535 avg loss: 1.852\n",
      "[Epoch 7, Batch 550] loss: 0.903  accuracy: 0.600 total accuracy: 0.537 avg loss: 1.851\n",
      "[Epoch 7, Batch 560] loss: 0.890  accuracy: 0.550 total accuracy: 0.537 avg loss: 1.850\n",
      "[Epoch 7, Batch 570] loss: 0.926  accuracy: 0.433 total accuracy: 0.535 avg loss: 1.850\n",
      "[Epoch 7, Batch 580] loss: 0.957  accuracy: 0.417 total accuracy: 0.533 avg loss: 1.851\n",
      "[Epoch 7, Batch 590] loss: 1.020  accuracy: 0.450 total accuracy: 0.532 avg loss: 1.854\n",
      "[Epoch 7, Batch 600] loss: 0.955  accuracy: 0.600 total accuracy: 0.533 avg loss: 1.855\n",
      "[Epoch 7, Batch 610] loss: 0.928  accuracy: 0.500 total accuracy: 0.532 avg loss: 1.855\n",
      "[Epoch 7, Batch 620] loss: 0.948  accuracy: 0.533 total accuracy: 0.532 avg loss: 1.856\n",
      "[Epoch 7, Batch 630] loss: 0.903  accuracy: 0.567 total accuracy: 0.533 avg loss: 1.855\n",
      "[Epoch 7, Batch 640] loss: 1.082  accuracy: 0.433 total accuracy: 0.531 avg loss: 1.860\n",
      "[Epoch 7, Batch 650] loss: 0.993  accuracy: 0.567 total accuracy: 0.532 avg loss: 1.862\n",
      "[Epoch 7, Batch 660] loss: 0.905  accuracy: 0.583 total accuracy: 0.533 avg loss: 1.861\n",
      "[Epoch 7, Batch 670] loss: 1.020  accuracy: 0.500 total accuracy: 0.532 avg loss: 1.864\n",
      "[Epoch 7, Batch 680] loss: 0.977  accuracy: 0.483 total accuracy: 0.531 avg loss: 1.865\n",
      "[Epoch 7, Batch 690] loss: 0.970  accuracy: 0.450 total accuracy: 0.530 avg loss: 1.866\n",
      "[Epoch 7, Batch 700] loss: 1.007  accuracy: 0.483 total accuracy: 0.530 avg loss: 1.868\n",
      "[Epoch 7, Batch 710] loss: 0.867  accuracy: 0.550 total accuracy: 0.530 avg loss: 1.866\n",
      "[Epoch 7, Batch 720] loss: 1.091  accuracy: 0.450 total accuracy: 0.529 avg loss: 1.871\n",
      "[Epoch 7, Batch 730] loss: 0.981  accuracy: 0.467 total accuracy: 0.528 avg loss: 1.872\n",
      "[Epoch 7, Batch 740] loss: 0.834  accuracy: 0.650 total accuracy: 0.530 avg loss: 1.869\n",
      "[Epoch 7, Batch 750] loss: 0.922  accuracy: 0.533 total accuracy: 0.530 avg loss: 1.869\n",
      "[Epoch 7, Batch 760] loss: 0.985  accuracy: 0.533 total accuracy: 0.530 avg loss: 1.870\n",
      "[Epoch 7, Batch 770] loss: 0.902  accuracy: 0.450 total accuracy: 0.529 avg loss: 1.869\n",
      "[Epoch 7, Batch 780] loss: 0.897  accuracy: 0.517 total accuracy: 0.528 avg loss: 1.868\n",
      "[Epoch 7, Batch 790] loss: 0.980  accuracy: 0.483 total accuracy: 0.528 avg loss: 1.869\n",
      "[Epoch 7, Batch 800] loss: 0.983  accuracy: 0.433 total accuracy: 0.527 avg loss: 1.871\n",
      "[Epoch 7, Batch 810] loss: 0.985  accuracy: 0.517 total accuracy: 0.527 avg loss: 1.872\n",
      "[Epoch 7, Batch 820] loss: 1.080  accuracy: 0.433 total accuracy: 0.525 avg loss: 1.875\n",
      "[Epoch 7, Batch 830] loss: 0.929  accuracy: 0.550 total accuracy: 0.526 avg loss: 1.875\n",
      "[Epoch 7, Batch 840] loss: 1.027  accuracy: 0.550 total accuracy: 0.526 avg loss: 1.877\n",
      "[Epoch 7, Batch 850] loss: 0.983  accuracy: 0.467 total accuracy: 0.525 avg loss: 1.878\n",
      "[Epoch 7, Batch 860] loss: 0.909  accuracy: 0.533 total accuracy: 0.525 avg loss: 1.878\n",
      "[Epoch 7, Batch 870] loss: 0.994  accuracy: 0.467 total accuracy: 0.525 avg loss: 1.879\n",
      "[Epoch 7, Batch 880] loss: 0.980  accuracy: 0.450 total accuracy: 0.524 avg loss: 1.880\n",
      "[Epoch 7, Batch 890] loss: 0.942  accuracy: 0.383 total accuracy: 0.522 avg loss: 1.880\n",
      "[Epoch 7, Batch 900] loss: 0.927  accuracy: 0.450 total accuracy: 0.521 avg loss: 1.880\n",
      "[Epoch 7, Batch 910] loss: 0.926  accuracy: 0.483 total accuracy: 0.521 avg loss: 1.879\n",
      "[Epoch 7, Batch 920] loss: 0.918  accuracy: 0.517 total accuracy: 0.521 avg loss: 1.879\n",
      "[Epoch 7, Batch 930] loss: 0.994  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.880\n",
      "[Epoch 7, Batch 940] loss: 0.996  accuracy: 0.483 total accuracy: 0.520 avg loss: 1.881\n",
      "[Epoch 7, Batch 950] loss: 0.897  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.880\n",
      "[Epoch 7, Batch 960] loss: 0.952  accuracy: 0.550 total accuracy: 0.521 avg loss: 1.881\n",
      "[Epoch 7, Batch 970] loss: 0.960  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.881\n",
      "Epoch 7 completed in 1135.61 seconds\n",
      "Validation loss after epoch 7: 1.880  accuracy: 0.531\n",
      "[Epoch 8, Batch 10] loss: 0.893  accuracy: 0.450 total accuracy: 0.450 avg loss: 1.785\n",
      "[Epoch 8, Batch 20] loss: 1.007  accuracy: 0.467 total accuracy: 0.458 avg loss: 1.899\n",
      "[Epoch 8, Batch 30] loss: 1.049  accuracy: 0.483 total accuracy: 0.467 avg loss: 1.965\n",
      "[Epoch 8, Batch 40] loss: 0.943  accuracy: 0.383 total accuracy: 0.446 avg loss: 1.945\n",
      "[Epoch 8, Batch 50] loss: 0.929  accuracy: 0.383 total accuracy: 0.433 avg loss: 1.928\n",
      "[Epoch 8, Batch 60] loss: 0.927  accuracy: 0.650 total accuracy: 0.469 avg loss: 1.916\n",
      "[Epoch 8, Batch 70] loss: 0.825  accuracy: 0.617 total accuracy: 0.490 avg loss: 1.878\n",
      "[Epoch 8, Batch 80] loss: 0.984  accuracy: 0.450 total accuracy: 0.485 avg loss: 1.889\n",
      "[Epoch 8, Batch 90] loss: 1.016  accuracy: 0.500 total accuracy: 0.487 avg loss: 1.905\n",
      "[Epoch 8, Batch 100] loss: 0.935  accuracy: 0.550 total accuracy: 0.493 avg loss: 1.901\n",
      "[Epoch 8, Batch 110] loss: 0.916  accuracy: 0.550 total accuracy: 0.498 avg loss: 1.895\n",
      "[Epoch 8, Batch 120] loss: 0.970  accuracy: 0.500 total accuracy: 0.499 avg loss: 1.899\n",
      "[Epoch 8, Batch 130] loss: 0.874  accuracy: 0.633 total accuracy: 0.509 avg loss: 1.887\n",
      "[Epoch 8, Batch 140] loss: 0.825  accuracy: 0.650 total accuracy: 0.519 avg loss: 1.870\n",
      "[Epoch 8, Batch 150] loss: 1.021  accuracy: 0.367 total accuracy: 0.509 avg loss: 1.882\n",
      "[Epoch 8, Batch 160] loss: 0.980  accuracy: 0.417 total accuracy: 0.503 avg loss: 1.887\n",
      "[Epoch 8, Batch 170] loss: 0.992  accuracy: 0.417 total accuracy: 0.498 avg loss: 1.892\n",
      "[Epoch 8, Batch 180] loss: 0.976  accuracy: 0.517 total accuracy: 0.499 avg loss: 1.896\n",
      "[Epoch 8, Batch 190] loss: 0.922  accuracy: 0.600 total accuracy: 0.504 avg loss: 1.893\n",
      "[Epoch 8, Batch 200] loss: 0.965  accuracy: 0.567 total accuracy: 0.507 avg loss: 1.895\n",
      "[Epoch 8, Batch 210] loss: 0.934  accuracy: 0.350 total accuracy: 0.500 avg loss: 1.894\n",
      "[Epoch 8, Batch 220] loss: 0.793  accuracy: 0.667 total accuracy: 0.508 avg loss: 1.880\n",
      "[Epoch 8, Batch 230] loss: 0.994  accuracy: 0.583 total accuracy: 0.511 avg loss: 1.884\n",
      "[Epoch 8, Batch 240] loss: 0.936  accuracy: 0.583 total accuracy: 0.514 avg loss: 1.884\n",
      "[Epoch 8, Batch 250] loss: 0.901  accuracy: 0.567 total accuracy: 0.516 avg loss: 1.881\n",
      "[Epoch 8, Batch 260] loss: 0.863  accuracy: 0.600 total accuracy: 0.519 avg loss: 1.875\n",
      "[Epoch 8, Batch 270] loss: 0.932  accuracy: 0.550 total accuracy: 0.520 avg loss: 1.874\n",
      "[Epoch 8, Batch 280] loss: 0.945  accuracy: 0.567 total accuracy: 0.522 avg loss: 1.875\n",
      "[Epoch 8, Batch 290] loss: 0.948  accuracy: 0.450 total accuracy: 0.520 avg loss: 1.876\n",
      "[Epoch 8, Batch 300] loss: 0.892  accuracy: 0.550 total accuracy: 0.521 avg loss: 1.872\n",
      "[Epoch 8, Batch 310] loss: 0.956  accuracy: 0.600 total accuracy: 0.523 avg loss: 1.874\n",
      "[Epoch 8, Batch 320] loss: 0.942  accuracy: 0.517 total accuracy: 0.523 avg loss: 1.874\n",
      "[Epoch 8, Batch 330] loss: 0.811  accuracy: 0.617 total accuracy: 0.526 avg loss: 1.866\n",
      "[Epoch 8, Batch 340] loss: 0.864  accuracy: 0.550 total accuracy: 0.526 avg loss: 1.862\n",
      "[Epoch 8, Batch 350] loss: 0.991  accuracy: 0.550 total accuracy: 0.527 avg loss: 1.866\n",
      "[Epoch 8, Batch 360] loss: 0.981  accuracy: 0.550 total accuracy: 0.528 avg loss: 1.868\n",
      "[Epoch 8, Batch 370] loss: 0.957  accuracy: 0.533 total accuracy: 0.528 avg loss: 1.870\n",
      "[Epoch 8, Batch 380] loss: 0.995  accuracy: 0.483 total accuracy: 0.527 avg loss: 1.873\n",
      "[Epoch 8, Batch 390] loss: 1.017  accuracy: 0.533 total accuracy: 0.527 avg loss: 1.877\n",
      "[Epoch 8, Batch 400] loss: 0.846  accuracy: 0.617 total accuracy: 0.529 avg loss: 1.872\n",
      "[Epoch 8, Batch 410] loss: 0.994  accuracy: 0.533 total accuracy: 0.529 avg loss: 1.875\n",
      "[Epoch 8, Batch 420] loss: 0.987  accuracy: 0.450 total accuracy: 0.527 avg loss: 1.878\n",
      "[Epoch 8, Batch 430] loss: 0.863  accuracy: 0.633 total accuracy: 0.530 avg loss: 1.874\n",
      "[Epoch 8, Batch 440] loss: 0.982  accuracy: 0.433 total accuracy: 0.528 avg loss: 1.876\n",
      "[Epoch 8, Batch 450] loss: 1.013  accuracy: 0.333 total accuracy: 0.523 avg loss: 1.879\n",
      "[Epoch 8, Batch 460] loss: 0.876  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.877\n",
      "[Epoch 8, Batch 470] loss: 0.995  accuracy: 0.383 total accuracy: 0.520 avg loss: 1.879\n",
      "[Epoch 8, Batch 480] loss: 0.856  accuracy: 0.617 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 8, Batch 490] loss: 1.063  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.881\n",
      "[Epoch 8, Batch 500] loss: 1.022  accuracy: 0.417 total accuracy: 0.519 avg loss: 1.884\n",
      "[Epoch 8, Batch 510] loss: 1.056  accuracy: 0.367 total accuracy: 0.516 avg loss: 1.888\n",
      "[Epoch 8, Batch 520] loss: 0.946  accuracy: 0.517 total accuracy: 0.516 avg loss: 1.889\n",
      "[Epoch 8, Batch 530] loss: 0.859  accuracy: 0.500 total accuracy: 0.516 avg loss: 1.885\n",
      "[Epoch 8, Batch 540] loss: 0.889  accuracy: 0.350 total accuracy: 0.513 avg loss: 1.883\n",
      "[Epoch 8, Batch 550] loss: 1.004  accuracy: 0.550 total accuracy: 0.513 avg loss: 1.886\n",
      "[Epoch 8, Batch 560] loss: 1.029  accuracy: 0.467 total accuracy: 0.512 avg loss: 1.889\n",
      "[Epoch 8, Batch 570] loss: 0.980  accuracy: 0.433 total accuracy: 0.511 avg loss: 1.890\n",
      "[Epoch 8, Batch 580] loss: 0.868  accuracy: 0.433 total accuracy: 0.510 avg loss: 1.887\n",
      "[Epoch 8, Batch 590] loss: 0.980  accuracy: 0.383 total accuracy: 0.508 avg loss: 1.888\n",
      "[Epoch 8, Batch 600] loss: 0.959  accuracy: 0.550 total accuracy: 0.508 avg loss: 1.889\n",
      "[Epoch 8, Batch 610] loss: 0.802  accuracy: 0.600 total accuracy: 0.510 avg loss: 1.884\n",
      "[Epoch 8, Batch 620] loss: 0.909  accuracy: 0.500 total accuracy: 0.510 avg loss: 1.883\n",
      "[Epoch 8, Batch 630] loss: 0.977  accuracy: 0.400 total accuracy: 0.508 avg loss: 1.884\n",
      "[Epoch 8, Batch 640] loss: 0.899  accuracy: 0.483 total accuracy: 0.508 avg loss: 1.883\n",
      "[Epoch 8, Batch 650] loss: 0.967  accuracy: 0.617 total accuracy: 0.509 avg loss: 1.884\n",
      "[Epoch 8, Batch 660] loss: 1.069  accuracy: 0.450 total accuracy: 0.508 avg loss: 1.888\n",
      "[Epoch 8, Batch 670] loss: 0.948  accuracy: 0.467 total accuracy: 0.508 avg loss: 1.888\n",
      "[Epoch 8, Batch 680] loss: 0.904  accuracy: 0.500 total accuracy: 0.508 avg loss: 1.887\n",
      "[Epoch 8, Batch 690] loss: 0.899  accuracy: 0.500 total accuracy: 0.507 avg loss: 1.885\n",
      "[Epoch 8, Batch 700] loss: 0.938  accuracy: 0.550 total accuracy: 0.508 avg loss: 1.885\n",
      "[Epoch 8, Batch 710] loss: 0.996  accuracy: 0.467 total accuracy: 0.508 avg loss: 1.887\n",
      "[Epoch 8, Batch 720] loss: 1.023  accuracy: 0.500 total accuracy: 0.507 avg loss: 1.889\n",
      "[Epoch 8, Batch 730] loss: 0.874  accuracy: 0.517 total accuracy: 0.508 avg loss: 1.887\n",
      "[Epoch 8, Batch 740] loss: 0.881  accuracy: 0.583 total accuracy: 0.509 avg loss: 1.885\n",
      "[Epoch 8, Batch 750] loss: 1.051  accuracy: 0.467 total accuracy: 0.508 avg loss: 1.888\n",
      "[Epoch 8, Batch 760] loss: 0.853  accuracy: 0.583 total accuracy: 0.509 avg loss: 1.886\n",
      "[Epoch 8, Batch 770] loss: 0.949  accuracy: 0.417 total accuracy: 0.508 avg loss: 1.886\n",
      "[Epoch 8, Batch 780] loss: 0.821  accuracy: 0.617 total accuracy: 0.509 avg loss: 1.883\n",
      "[Epoch 8, Batch 790] loss: 1.003  accuracy: 0.483 total accuracy: 0.509 avg loss: 1.884\n",
      "[Epoch 8, Batch 800] loss: 0.977  accuracy: 0.567 total accuracy: 0.510 avg loss: 1.885\n",
      "[Epoch 8, Batch 810] loss: 0.865  accuracy: 0.600 total accuracy: 0.511 avg loss: 1.883\n",
      "[Epoch 8, Batch 820] loss: 0.919  accuracy: 0.517 total accuracy: 0.511 avg loss: 1.883\n",
      "[Epoch 8, Batch 830] loss: 1.032  accuracy: 0.517 total accuracy: 0.511 avg loss: 1.885\n",
      "[Epoch 8, Batch 840] loss: 0.885  accuracy: 0.600 total accuracy: 0.512 avg loss: 1.884\n",
      "[Epoch 8, Batch 850] loss: 0.956  accuracy: 0.533 total accuracy: 0.512 avg loss: 1.884\n",
      "[Epoch 8, Batch 860] loss: 0.912  accuracy: 0.500 total accuracy: 0.512 avg loss: 1.883\n",
      "[Epoch 8, Batch 870] loss: 0.965  accuracy: 0.567 total accuracy: 0.513 avg loss: 1.884\n",
      "[Epoch 8, Batch 880] loss: 0.989  accuracy: 0.550 total accuracy: 0.513 avg loss: 1.885\n",
      "[Epoch 8, Batch 890] loss: 0.833  accuracy: 0.633 total accuracy: 0.514 avg loss: 1.882\n",
      "[Epoch 8, Batch 900] loss: 0.881  accuracy: 0.567 total accuracy: 0.515 avg loss: 1.881\n",
      "[Epoch 8, Batch 910] loss: 0.919  accuracy: 0.567 total accuracy: 0.516 avg loss: 1.881\n",
      "[Epoch 8, Batch 920] loss: 0.973  accuracy: 0.467 total accuracy: 0.515 avg loss: 1.881\n",
      "[Epoch 8, Batch 930] loss: 0.986  accuracy: 0.467 total accuracy: 0.515 avg loss: 1.882\n",
      "[Epoch 8, Batch 940] loss: 1.006  accuracy: 0.517 total accuracy: 0.515 avg loss: 1.884\n",
      "[Epoch 8, Batch 950] loss: 0.968  accuracy: 0.567 total accuracy: 0.515 avg loss: 1.884\n",
      "[Epoch 8, Batch 960] loss: 1.024  accuracy: 0.450 total accuracy: 0.514 avg loss: 1.886\n",
      "[Epoch 8, Batch 970] loss: 0.943  accuracy: 0.517 total accuracy: 0.514 avg loss: 1.886\n",
      "Epoch 8 completed in 1044.21 seconds\n",
      "Validation loss after epoch 8: 1.886  accuracy: 0.531\n",
      "[Epoch 9, Batch 10] loss: 0.953  accuracy: 0.550 total accuracy: 0.550 avg loss: 1.906\n",
      "[Epoch 9, Batch 20] loss: 0.867  accuracy: 0.567 total accuracy: 0.558 avg loss: 1.820\n",
      "[Epoch 9, Batch 30] loss: 0.926  accuracy: 0.500 total accuracy: 0.539 avg loss: 1.831\n",
      "[Epoch 9, Batch 40] loss: 1.000  accuracy: 0.467 total accuracy: 0.521 avg loss: 1.873\n",
      "[Epoch 9, Batch 50] loss: 1.027  accuracy: 0.517 total accuracy: 0.520 avg loss: 1.909\n",
      "[Epoch 9, Batch 60] loss: 1.005  accuracy: 0.517 total accuracy: 0.519 avg loss: 1.926\n",
      "[Epoch 9, Batch 70] loss: 0.966  accuracy: 0.500 total accuracy: 0.517 avg loss: 1.927\n",
      "[Epoch 9, Batch 80] loss: 1.005  accuracy: 0.500 total accuracy: 0.515 avg loss: 1.937\n",
      "[Epoch 9, Batch 90] loss: 1.002  accuracy: 0.500 total accuracy: 0.513 avg loss: 1.945\n",
      "[Epoch 9, Batch 100] loss: 0.890  accuracy: 0.633 total accuracy: 0.525 avg loss: 1.928\n",
      "[Epoch 9, Batch 110] loss: 0.965  accuracy: 0.467 total accuracy: 0.520 avg loss: 1.928\n",
      "[Epoch 9, Batch 120] loss: 0.932  accuracy: 0.500 total accuracy: 0.518 avg loss: 1.923\n",
      "[Epoch 9, Batch 130] loss: 0.961  accuracy: 0.450 total accuracy: 0.513 avg loss: 1.923\n",
      "[Epoch 9, Batch 140] loss: 0.930  accuracy: 0.467 total accuracy: 0.510 avg loss: 1.918\n",
      "[Epoch 9, Batch 150] loss: 0.927  accuracy: 0.617 total accuracy: 0.517 avg loss: 1.914\n",
      "[Epoch 9, Batch 160] loss: 0.930  accuracy: 0.550 total accuracy: 0.519 avg loss: 1.911\n",
      "[Epoch 9, Batch 170] loss: 1.005  accuracy: 0.567 total accuracy: 0.522 avg loss: 1.917\n",
      "[Epoch 9, Batch 180] loss: 0.873  accuracy: 0.550 total accuracy: 0.523 avg loss: 1.907\n",
      "[Epoch 9, Batch 190] loss: 1.019  accuracy: 0.517 total accuracy: 0.523 avg loss: 1.914\n",
      "[Epoch 9, Batch 200] loss: 0.976  accuracy: 0.483 total accuracy: 0.521 avg loss: 1.916\n",
      "[Epoch 9, Batch 210] loss: 0.944  accuracy: 0.517 total accuracy: 0.521 avg loss: 1.915\n",
      "[Epoch 9, Batch 220] loss: 0.842  accuracy: 0.583 total accuracy: 0.523 avg loss: 1.904\n",
      "[Epoch 9, Batch 230] loss: 0.900  accuracy: 0.617 total accuracy: 0.528 avg loss: 1.900\n",
      "[Epoch 9, Batch 240] loss: 0.839  accuracy: 0.600 total accuracy: 0.531 avg loss: 1.890\n",
      "[Epoch 9, Batch 250] loss: 0.855  accuracy: 0.567 total accuracy: 0.532 avg loss: 1.883\n",
      "[Epoch 9, Batch 260] loss: 0.915  accuracy: 0.583 total accuracy: 0.534 avg loss: 1.881\n",
      "[Epoch 9, Batch 270] loss: 1.042  accuracy: 0.417 total accuracy: 0.530 avg loss: 1.889\n",
      "[Epoch 9, Batch 280] loss: 0.896  accuracy: 0.517 total accuracy: 0.529 avg loss: 1.885\n",
      "[Epoch 9, Batch 290] loss: 0.993  accuracy: 0.517 total accuracy: 0.529 avg loss: 1.889\n",
      "[Epoch 9, Batch 300] loss: 0.859  accuracy: 0.567 total accuracy: 0.530 avg loss: 1.883\n",
      "[Epoch 9, Batch 310] loss: 1.017  accuracy: 0.500 total accuracy: 0.529 avg loss: 1.888\n",
      "[Epoch 9, Batch 320] loss: 0.946  accuracy: 0.500 total accuracy: 0.528 avg loss: 1.888\n",
      "[Epoch 9, Batch 330] loss: 0.795  accuracy: 0.617 total accuracy: 0.531 avg loss: 1.879\n",
      "[Epoch 9, Batch 340] loss: 1.033  accuracy: 0.467 total accuracy: 0.529 avg loss: 1.884\n",
      "[Epoch 9, Batch 350] loss: 0.951  accuracy: 0.550 total accuracy: 0.530 avg loss: 1.885\n",
      "[Epoch 9, Batch 360] loss: 1.033  accuracy: 0.500 total accuracy: 0.529 avg loss: 1.890\n",
      "[Epoch 9, Batch 370] loss: 0.958  accuracy: 0.467 total accuracy: 0.527 avg loss: 1.891\n",
      "[Epoch 9, Batch 380] loss: 0.952  accuracy: 0.483 total accuracy: 0.526 avg loss: 1.891\n",
      "[Epoch 9, Batch 390] loss: 0.878  accuracy: 0.600 total accuracy: 0.528 avg loss: 1.888\n",
      "[Epoch 9, Batch 400] loss: 0.946  accuracy: 0.500 total accuracy: 0.527 avg loss: 1.888\n",
      "[Epoch 9, Batch 410] loss: 1.041  accuracy: 0.533 total accuracy: 0.527 avg loss: 1.892\n",
      "[Epoch 9, Batch 420] loss: 0.996  accuracy: 0.533 total accuracy: 0.527 avg loss: 1.895\n",
      "[Epoch 9, Batch 430] loss: 0.932  accuracy: 0.583 total accuracy: 0.529 avg loss: 1.894\n",
      "[Epoch 9, Batch 440] loss: 0.924  accuracy: 0.450 total accuracy: 0.527 avg loss: 1.893\n",
      "[Epoch 9, Batch 450] loss: 0.901  accuracy: 0.517 total accuracy: 0.527 avg loss: 1.891\n",
      "[Epoch 9, Batch 460] loss: 0.883  accuracy: 0.483 total accuracy: 0.526 avg loss: 1.888\n",
      "[Epoch 9, Batch 470] loss: 0.934  accuracy: 0.550 total accuracy: 0.526 avg loss: 1.888\n",
      "[Epoch 9, Batch 480] loss: 0.911  accuracy: 0.400 total accuracy: 0.524 avg loss: 1.886\n",
      "[Epoch 9, Batch 490] loss: 0.986  accuracy: 0.400 total accuracy: 0.521 avg loss: 1.888\n",
      "[Epoch 9, Batch 500] loss: 0.919  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.887\n",
      "[Epoch 9, Batch 510] loss: 0.897  accuracy: 0.600 total accuracy: 0.522 avg loss: 1.885\n",
      "[Epoch 9, Batch 520] loss: 0.879  accuracy: 0.567 total accuracy: 0.523 avg loss: 1.883\n",
      "[Epoch 9, Batch 530] loss: 1.027  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.886\n",
      "[Epoch 9, Batch 540] loss: 0.909  accuracy: 0.600 total accuracy: 0.524 avg loss: 1.885\n",
      "[Epoch 9, Batch 550] loss: 0.956  accuracy: 0.483 total accuracy: 0.523 avg loss: 1.885\n",
      "[Epoch 9, Batch 560] loss: 0.967  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.886\n",
      "[Epoch 9, Batch 570] loss: 0.901  accuracy: 0.633 total accuracy: 0.525 avg loss: 1.885\n",
      "[Epoch 9, Batch 580] loss: 0.899  accuracy: 0.517 total accuracy: 0.524 avg loss: 1.883\n",
      "[Epoch 9, Batch 590] loss: 0.882  accuracy: 0.483 total accuracy: 0.524 avg loss: 1.881\n",
      "[Epoch 9, Batch 600] loss: 0.900  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.880\n",
      "[Epoch 9, Batch 610] loss: 0.923  accuracy: 0.517 total accuracy: 0.523 avg loss: 1.879\n",
      "[Epoch 9, Batch 620] loss: 1.008  accuracy: 0.467 total accuracy: 0.522 avg loss: 1.882\n",
      "[Epoch 9, Batch 630] loss: 0.915  accuracy: 0.433 total accuracy: 0.521 avg loss: 1.881\n",
      "[Epoch 9, Batch 640] loss: 0.918  accuracy: 0.617 total accuracy: 0.522 avg loss: 1.880\n",
      "[Epoch 9, Batch 650] loss: 0.917  accuracy: 0.517 total accuracy: 0.522 avg loss: 1.879\n",
      "[Epoch 9, Batch 660] loss: 0.982  accuracy: 0.533 total accuracy: 0.522 avg loss: 1.881\n",
      "[Epoch 9, Batch 670] loss: 0.980  accuracy: 0.467 total accuracy: 0.522 avg loss: 1.882\n",
      "[Epoch 9, Batch 680] loss: 0.929  accuracy: 0.550 total accuracy: 0.522 avg loss: 1.881\n",
      "[Epoch 9, Batch 690] loss: 0.962  accuracy: 0.517 total accuracy: 0.522 avg loss: 1.882\n",
      "[Epoch 9, Batch 700] loss: 0.965  accuracy: 0.450 total accuracy: 0.521 avg loss: 1.883\n",
      "[Epoch 9, Batch 710] loss: 0.866  accuracy: 0.550 total accuracy: 0.521 avg loss: 1.881\n",
      "[Epoch 9, Batch 720] loss: 0.863  accuracy: 0.633 total accuracy: 0.523 avg loss: 1.878\n",
      "[Epoch 9, Batch 730] loss: 1.044  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.881\n",
      "[Epoch 9, Batch 740] loss: 0.894  accuracy: 0.583 total accuracy: 0.523 avg loss: 1.880\n",
      "[Epoch 9, Batch 750] loss: 0.886  accuracy: 0.550 total accuracy: 0.524 avg loss: 1.879\n",
      "[Epoch 9, Batch 760] loss: 0.893  accuracy: 0.583 total accuracy: 0.524 avg loss: 1.877\n",
      "[Epoch 9, Batch 770] loss: 1.014  accuracy: 0.550 total accuracy: 0.525 avg loss: 1.879\n",
      "[Epoch 9, Batch 780] loss: 0.887  accuracy: 0.550 total accuracy: 0.525 avg loss: 1.878\n",
      "[Epoch 9, Batch 790] loss: 0.928  accuracy: 0.550 total accuracy: 0.525 avg loss: 1.878\n",
      "[Epoch 9, Batch 800] loss: 0.805  accuracy: 0.583 total accuracy: 0.526 avg loss: 1.874\n",
      "[Epoch 9, Batch 810] loss: 0.929  accuracy: 0.500 total accuracy: 0.526 avg loss: 1.874\n",
      "[Epoch 9, Batch 820] loss: 0.891  accuracy: 0.583 total accuracy: 0.526 avg loss: 1.873\n",
      "[Epoch 9, Batch 830] loss: 0.891  accuracy: 0.583 total accuracy: 0.527 avg loss: 1.872\n",
      "[Epoch 9, Batch 840] loss: 0.826  accuracy: 0.617 total accuracy: 0.528 avg loss: 1.869\n",
      "[Epoch 9, Batch 850] loss: 1.151  accuracy: 0.450 total accuracy: 0.527 avg loss: 1.874\n",
      "[Epoch 9, Batch 860] loss: 0.953  accuracy: 0.433 total accuracy: 0.526 avg loss: 1.875\n",
      "[Epoch 9, Batch 870] loss: 1.060  accuracy: 0.400 total accuracy: 0.525 avg loss: 1.878\n",
      "[Epoch 9, Batch 880] loss: 1.002  accuracy: 0.350 total accuracy: 0.523 avg loss: 1.879\n",
      "[Epoch 9, Batch 890] loss: 0.876  accuracy: 0.583 total accuracy: 0.523 avg loss: 1.878\n",
      "[Epoch 9, Batch 900] loss: 0.945  accuracy: 0.517 total accuracy: 0.523 avg loss: 1.878\n",
      "[Epoch 9, Batch 910] loss: 0.870  accuracy: 0.417 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 9, Batch 920] loss: 0.991  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.877\n",
      "[Epoch 9, Batch 930] loss: 0.951  accuracy: 0.450 total accuracy: 0.521 avg loss: 1.878\n",
      "[Epoch 9, Batch 940] loss: 0.939  accuracy: 0.550 total accuracy: 0.521 avg loss: 1.878\n",
      "[Epoch 9, Batch 950] loss: 0.861  accuracy: 0.633 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 9, Batch 960] loss: 0.954  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 9, Batch 970] loss: 0.921  accuracy: 0.500 total accuracy: 0.522 avg loss: 1.876\n",
      "Epoch 9 completed in 1021.77 seconds\n",
      "Validation loss after epoch 9: 1.889  accuracy: 0.531\n",
      "[Epoch 10, Batch 10] loss: 0.913  accuracy: 0.600 total accuracy: 0.600 avg loss: 1.827\n",
      "[Epoch 10, Batch 20] loss: 0.987  accuracy: 0.567 total accuracy: 0.583 avg loss: 1.901\n",
      "[Epoch 10, Batch 30] loss: 0.983  accuracy: 0.500 total accuracy: 0.556 avg loss: 1.923\n",
      "[Epoch 10, Batch 40] loss: 0.967  accuracy: 0.517 total accuracy: 0.546 avg loss: 1.925\n",
      "[Epoch 10, Batch 50] loss: 1.011  accuracy: 0.600 total accuracy: 0.557 avg loss: 1.945\n",
      "[Epoch 10, Batch 60] loss: 0.822  accuracy: 0.617 total accuracy: 0.567 avg loss: 1.895\n",
      "[Epoch 10, Batch 70] loss: 0.847  accuracy: 0.567 total accuracy: 0.567 avg loss: 1.866\n",
      "[Epoch 10, Batch 80] loss: 0.893  accuracy: 0.583 total accuracy: 0.569 avg loss: 1.856\n",
      "[Epoch 10, Batch 90] loss: 0.850  accuracy: 0.617 total accuracy: 0.574 avg loss: 1.838\n",
      "[Epoch 10, Batch 100] loss: 0.997  accuracy: 0.417 total accuracy: 0.558 avg loss: 1.854\n",
      "[Epoch 10, Batch 110] loss: 0.911  accuracy: 0.533 total accuracy: 0.556 avg loss: 1.851\n",
      "[Epoch 10, Batch 120] loss: 0.975  accuracy: 0.483 total accuracy: 0.550 avg loss: 1.859\n",
      "[Epoch 10, Batch 130] loss: 1.000  accuracy: 0.450 total accuracy: 0.542 avg loss: 1.870\n",
      "[Epoch 10, Batch 140] loss: 0.983  accuracy: 0.417 total accuracy: 0.533 avg loss: 1.877\n",
      "[Epoch 10, Batch 150] loss: 0.930  accuracy: 0.400 total accuracy: 0.524 avg loss: 1.876\n",
      "[Epoch 10, Batch 160] loss: 1.060  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.891\n",
      "[Epoch 10, Batch 170] loss: 1.015  accuracy: 0.417 total accuracy: 0.517 avg loss: 1.899\n",
      "[Epoch 10, Batch 180] loss: 0.885  accuracy: 0.583 total accuracy: 0.520 avg loss: 1.892\n",
      "[Epoch 10, Batch 190] loss: 0.983  accuracy: 0.467 total accuracy: 0.518 avg loss: 1.896\n",
      "[Epoch 10, Batch 200] loss: 0.936  accuracy: 0.533 total accuracy: 0.518 avg loss: 1.895\n",
      "[Epoch 10, Batch 210] loss: 0.870  accuracy: 0.517 total accuracy: 0.518 avg loss: 1.887\n",
      "[Epoch 10, Batch 220] loss: 0.952  accuracy: 0.483 total accuracy: 0.517 avg loss: 1.888\n",
      "[Epoch 10, Batch 230] loss: 0.988  accuracy: 0.417 total accuracy: 0.512 avg loss: 1.892\n",
      "[Epoch 10, Batch 240] loss: 0.943  accuracy: 0.517 total accuracy: 0.512 avg loss: 1.892\n",
      "[Epoch 10, Batch 250] loss: 0.898  accuracy: 0.483 total accuracy: 0.511 avg loss: 1.888\n",
      "[Epoch 10, Batch 260] loss: 0.883  accuracy: 0.583 total accuracy: 0.514 avg loss: 1.883\n",
      "[Epoch 10, Batch 270] loss: 0.965  accuracy: 0.633 total accuracy: 0.519 avg loss: 1.885\n",
      "[Epoch 10, Batch 280] loss: 1.065  accuracy: 0.483 total accuracy: 0.517 avg loss: 1.894\n",
      "[Epoch 10, Batch 290] loss: 0.908  accuracy: 0.550 total accuracy: 0.518 avg loss: 1.891\n",
      "[Epoch 10, Batch 300] loss: 0.925  accuracy: 0.517 total accuracy: 0.518 avg loss: 1.890\n",
      "[Epoch 10, Batch 310] loss: 0.900  accuracy: 0.617 total accuracy: 0.522 avg loss: 1.887\n",
      "[Epoch 10, Batch 320] loss: 0.907  accuracy: 0.550 total accuracy: 0.522 avg loss: 1.885\n",
      "[Epoch 10, Batch 330] loss: 0.909  accuracy: 0.500 total accuracy: 0.522 avg loss: 1.883\n",
      "[Epoch 10, Batch 340] loss: 0.995  accuracy: 0.600 total accuracy: 0.524 avg loss: 1.886\n",
      "[Epoch 10, Batch 350] loss: 0.954  accuracy: 0.533 total accuracy: 0.524 avg loss: 1.886\n",
      "[Epoch 10, Batch 360] loss: 0.883  accuracy: 0.600 total accuracy: 0.526 avg loss: 1.883\n",
      "[Epoch 10, Batch 370] loss: 1.003  accuracy: 0.517 total accuracy: 0.526 avg loss: 1.886\n",
      "[Epoch 10, Batch 380] loss: 0.875  accuracy: 0.650 total accuracy: 0.529 avg loss: 1.883\n",
      "[Epoch 10, Batch 390] loss: 1.094  accuracy: 0.417 total accuracy: 0.526 avg loss: 1.891\n",
      "[Epoch 10, Batch 400] loss: 0.964  accuracy: 0.550 total accuracy: 0.527 avg loss: 1.891\n",
      "[Epoch 10, Batch 410] loss: 0.879  accuracy: 0.517 total accuracy: 0.527 avg loss: 1.888\n",
      "[Epoch 10, Batch 420] loss: 0.860  accuracy: 0.533 total accuracy: 0.527 avg loss: 1.884\n",
      "[Epoch 10, Batch 430] loss: 0.902  accuracy: 0.450 total accuracy: 0.525 avg loss: 1.882\n",
      "[Epoch 10, Batch 440] loss: 0.961  accuracy: 0.417 total accuracy: 0.523 avg loss: 1.883\n",
      "[Epoch 10, Batch 450] loss: 1.004  accuracy: 0.500 total accuracy: 0.522 avg loss: 1.886\n",
      "[Epoch 10, Batch 460] loss: 0.935  accuracy: 0.533 total accuracy: 0.522 avg loss: 1.886\n",
      "[Epoch 10, Batch 470] loss: 0.955  accuracy: 0.517 total accuracy: 0.522 avg loss: 1.886\n",
      "[Epoch 10, Batch 480] loss: 0.828  accuracy: 0.650 total accuracy: 0.525 avg loss: 1.881\n",
      "[Epoch 10, Batch 490] loss: 0.970  accuracy: 0.600 total accuracy: 0.527 avg loss: 1.883\n",
      "[Epoch 10, Batch 500] loss: 0.836  accuracy: 0.533 total accuracy: 0.527 avg loss: 1.878\n",
      "[Epoch 10, Batch 510] loss: 1.027  accuracy: 0.550 total accuracy: 0.527 avg loss: 1.882\n",
      "[Epoch 10, Batch 520] loss: 1.006  accuracy: 0.450 total accuracy: 0.526 avg loss: 1.884\n",
      "[Epoch 10, Batch 530] loss: 1.026  accuracy: 0.533 total accuracy: 0.526 avg loss: 1.887\n",
      "[Epoch 10, Batch 540] loss: 0.916  accuracy: 0.583 total accuracy: 0.527 avg loss: 1.886\n",
      "[Epoch 10, Batch 550] loss: 0.977  accuracy: 0.483 total accuracy: 0.526 avg loss: 1.888\n",
      "[Epoch 10, Batch 560] loss: 0.972  accuracy: 0.483 total accuracy: 0.525 avg loss: 1.889\n",
      "[Epoch 10, Batch 570] loss: 0.926  accuracy: 0.450 total accuracy: 0.524 avg loss: 1.888\n",
      "[Epoch 10, Batch 580] loss: 0.951  accuracy: 0.483 total accuracy: 0.523 avg loss: 1.888\n",
      "[Epoch 10, Batch 590] loss: 1.020  accuracy: 0.467 total accuracy: 0.522 avg loss: 1.891\n",
      "[Epoch 10, Batch 600] loss: 0.953  accuracy: 0.467 total accuracy: 0.521 avg loss: 1.891\n",
      "[Epoch 10, Batch 610] loss: 0.945  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.891\n",
      "[Epoch 10, Batch 620] loss: 0.835  accuracy: 0.600 total accuracy: 0.522 avg loss: 1.887\n",
      "[Epoch 10, Batch 630] loss: 0.890  accuracy: 0.533 total accuracy: 0.522 avg loss: 1.886\n",
      "[Epoch 10, Batch 640] loss: 0.950  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.886\n",
      "[Epoch 10, Batch 650] loss: 0.886  accuracy: 0.533 total accuracy: 0.522 avg loss: 1.884\n",
      "[Epoch 10, Batch 660] loss: 0.931  accuracy: 0.450 total accuracy: 0.521 avg loss: 1.884\n",
      "[Epoch 10, Batch 670] loss: 0.913  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.883\n",
      "[Epoch 10, Batch 680] loss: 0.920  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.882\n",
      "[Epoch 10, Batch 690] loss: 0.939  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.882\n",
      "[Epoch 10, Batch 700] loss: 0.938  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.882\n",
      "[Epoch 10, Batch 710] loss: 0.960  accuracy: 0.533 total accuracy: 0.521 avg loss: 1.883\n",
      "[Epoch 10, Batch 720] loss: 0.964  accuracy: 0.517 total accuracy: 0.521 avg loss: 1.883\n",
      "[Epoch 10, Batch 730] loss: 0.877  accuracy: 0.567 total accuracy: 0.522 avg loss: 1.882\n",
      "[Epoch 10, Batch 740] loss: 0.893  accuracy: 0.583 total accuracy: 0.523 avg loss: 1.880\n",
      "[Epoch 10, Batch 750] loss: 0.948  accuracy: 0.500 total accuracy: 0.522 avg loss: 1.881\n",
      "[Epoch 10, Batch 760] loss: 0.884  accuracy: 0.550 total accuracy: 0.523 avg loss: 1.879\n",
      "[Epoch 10, Batch 770] loss: 0.854  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.877\n",
      "[Epoch 10, Batch 780] loss: 0.852  accuracy: 0.567 total accuracy: 0.523 avg loss: 1.875\n",
      "[Epoch 10, Batch 790] loss: 0.780  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.871\n",
      "[Epoch 10, Batch 800] loss: 0.865  accuracy: 0.483 total accuracy: 0.522 avg loss: 1.869\n",
      "[Epoch 10, Batch 810] loss: 0.899  accuracy: 0.500 total accuracy: 0.522 avg loss: 1.868\n",
      "[Epoch 10, Batch 820] loss: 0.794  accuracy: 0.667 total accuracy: 0.524 avg loss: 1.865\n",
      "[Epoch 10, Batch 830] loss: 0.900  accuracy: 0.583 total accuracy: 0.524 avg loss: 1.864\n",
      "[Epoch 10, Batch 840] loss: 1.060  accuracy: 0.550 total accuracy: 0.525 avg loss: 1.867\n",
      "[Epoch 10, Batch 850] loss: 0.933  accuracy: 0.600 total accuracy: 0.526 avg loss: 1.867\n",
      "[Epoch 10, Batch 860] loss: 0.969  accuracy: 0.517 total accuracy: 0.526 avg loss: 1.868\n",
      "[Epoch 10, Batch 870] loss: 0.998  accuracy: 0.517 total accuracy: 0.525 avg loss: 1.869\n",
      "[Epoch 10, Batch 880] loss: 1.017  accuracy: 0.383 total accuracy: 0.524 avg loss: 1.871\n",
      "[Epoch 10, Batch 890] loss: 1.055  accuracy: 0.500 total accuracy: 0.524 avg loss: 1.874\n",
      "[Epoch 10, Batch 900] loss: 0.903  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.873\n",
      "[Epoch 10, Batch 910] loss: 0.914  accuracy: 0.533 total accuracy: 0.523 avg loss: 1.873\n",
      "[Epoch 10, Batch 920] loss: 0.998  accuracy: 0.500 total accuracy: 0.523 avg loss: 1.874\n",
      "[Epoch 10, Batch 930] loss: 1.049  accuracy: 0.450 total accuracy: 0.522 avg loss: 1.876\n",
      "[Epoch 10, Batch 940] loss: 0.969  accuracy: 0.533 total accuracy: 0.523 avg loss: 1.877\n",
      "[Epoch 10, Batch 950] loss: 0.960  accuracy: 0.450 total accuracy: 0.522 avg loss: 1.877\n",
      "[Epoch 10, Batch 960] loss: 0.970  accuracy: 0.483 total accuracy: 0.521 avg loss: 1.878\n",
      "[Epoch 10, Batch 970] loss: 0.947  accuracy: 0.500 total accuracy: 0.521 avg loss: 1.878\n",
      "Epoch 10 completed in 1021.76 seconds\n",
      "Validation loss after epoch 10: 1.884  accuracy: 0.531\n",
      "Model saved to model.pth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Training loop with extra logging\n",
    "global_step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train_batch = 0\n",
    "    correct_total = 0\n",
    "    total_train_batch = 0\n",
    "    total_train = 0\n",
    "    total_loss = 0.0\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        mlo, cc = inputs\n",
    "        mlo_labels, cc_labels = labels\n",
    "        mlo = mlo.to(device)\n",
    "        cc = cc.to(device)\n",
    "        mlo_labels = mlo_labels.to(device).long()\n",
    "        cc_labels = cc_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model_input = torch.cat((mlo, cc), dim=0)\n",
    "        outputs = model(model_input)\n",
    "        \n",
    "        mlo_outputs, cc_outputs = torch.split(outputs, mlo.size(0), dim=0)\n",
    "        \n",
    "        # mlo_outputs, cc_outputs = model(mlo, cc)\n",
    "        \n",
    "        # Ensure the batch sizes match\n",
    "        mlo_outputs = mlo_outputs.view(-1, num_classes)\n",
    "        cc_outputs = cc_outputs.view(-1, num_classes)\n",
    "        mlo_labels = mlo_labels.view(-1)\n",
    "        cc_labels = cc_labels.view(-1)\n",
    "        \n",
    "        loss = criterion(mlo_outputs, mlo_labels) + criterion(cc_outputs, cc_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # Compute predictions\n",
    "        _, mlo_preds = torch.max(mlo_outputs, 1)\n",
    "        _, cc_preds = torch.max(cc_outputs, 1)\n",
    "        \n",
    "        correct_train_batch += torch.sum(mlo_preds == mlo_labels).item() + torch.sum(cc_preds == cc_labels).item()\n",
    "        \n",
    "        \n",
    "        total_train_batch += mlo_labels.size(0) + cc_labels.size(0)\n",
    "        global_step += 1\n",
    "        \n",
    "        # _, preds = torch.max(outputs, 1)\n",
    "        # correct_train += torch.sum(preds == labels).item()\n",
    "        # total_train += labels.size(0)\n",
    "        # global_step += 1\n",
    "        \n",
    "        if i % 10 == 9:\n",
    "            avg_loss = running_loss / 10 / 2\n",
    "            \n",
    "            total_train += total_train_batch\n",
    "            correct_total += correct_train_batch\n",
    "            total_loss += running_loss\n",
    "            \n",
    "            avg_total_loss = total_loss / (i+1)\n",
    "            \n",
    "            train_acc_batch = correct_train_batch / total_train_batch\n",
    "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {avg_loss:.3f}  accuracy: {train_acc_batch:.3f} total accuracy: {correct_total / total_train:.3f} avg loss: {avg_total_loss:.3f}\")\n",
    "            writer.add_scalar('training loss', avg_loss, global_step)\n",
    "            writer.add_scalar('training accuracy', train_acc_batch, global_step)\n",
    "            \n",
    "            writer.add_scalar('total training accuracy', correct_total / total_train, global_step)\n",
    "            writer.add_scalar('total training loss', avg_total_loss, global_step)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            correct_train_batch = 0\n",
    "            total_train_batch = 0\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time:.2f} seconds\")\n",
    "    \n",
    "    # Validation loop with same logic as training\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_batch = 0\n",
    "    total_batch = 0\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels = data\n",
    "            mlo, cc = inputs\n",
    "            mlo_labels, cc_labels = labels\n",
    "            mlo = mlo.to(device)\n",
    "            cc = cc.to(device)\n",
    "            mlo_labels = mlo_labels.to(device).long()\n",
    "            cc_labels = cc_labels.to(device).long()\n",
    "            model_input = torch.cat((mlo, cc), dim=0)\n",
    "            outputs = model(model_input)\n",
    "            mlo_outputs, cc_outputs = torch.split(outputs, mlo.size(0), dim=0)\n",
    "            mlo_outputs = mlo_outputs.view(-1, num_classes)\n",
    "            cc_outputs = cc_outputs.view(-1, num_classes)\n",
    "            mlo_labels = mlo_labels.view(-1)\n",
    "            cc_labels = cc_labels.view(-1)\n",
    "            loss = criterion(mlo_outputs, mlo_labels) + criterion(cc_outputs, cc_labels)\n",
    "            running_loss += loss.item()\n",
    "            _, mlo_preds = torch.max(mlo_outputs, 1)\n",
    "            _, cc_preds = torch.max(cc_outputs, 1)\n",
    "            correct = torch.sum(mlo_preds == mlo_labels).item() + torch.sum(cc_preds == cc_labels).item()\n",
    "            batch_total = mlo_labels.size(0) + cc_labels.size(0)\n",
    "            correct_batch += correct\n",
    "            total_batch += batch_total\n",
    "            total_loss += loss.item()\n",
    "            total_correct += correct\n",
    "            total_samples += batch_total\n",
    "            if i % 10 == 9:\n",
    "                avg_loss = running_loss / 10 / 2\n",
    "                batch_acc = correct_batch / total_batch\n",
    "                writer.add_scalar('validation loss', avg_loss, i)\n",
    "                writer.add_scalar('validation accuracy', batch_acc, i)\n",
    "                running_loss = 0.0\n",
    "                correct_batch = 0\n",
    "                total_batch = 0\n",
    "    val_loss_avg = total_loss / len(val_loader) / 2\n",
    "    val_acc = total_correct / total_samples\n",
    "    print(f\"Validation loss after epoch {epoch+1}: {val_loss_avg:.3f}  accuracy: {val_acc:.3f}\")\n",
    "    writer.add_scalar('validation loss', val_loss_avg, epoch)\n",
    "    writer.add_scalar('validation accuracy', val_acc, epoch)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), f\"model_{experiment}.pth\")\n",
    "print(\"Model saved to model.pth\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
